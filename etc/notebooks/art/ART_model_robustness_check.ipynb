{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ART to Generate Adversarial Samples for a Deep Learning Model\n",
    "\n",
    "This notebook shows how to use adversarial attack techniques from *Adversarial Robustness Toolbox* (*ART*) with *FfDL*. The ART library supports crafting and analyzing different attack and defense methods for deep learning models. \n",
    "\n",
    "In this notebook, you will learn how to incorporate one of the attack methods supported by ART, the *Fast Gradient Method* (*FGM*) into your training pipeline to generate adversarial samples for the purposes of evaluating the robustness of the trained model. In particular, the example in this notebook trains a *CNN* model on *MNIST* data and evaluates its robustness. \n",
    "\n",
    "The **ART** Github repository can be found here - https://github.com/IBM/adversarial-robustness-toolbox\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1.\t[Set up the environment](#setup)\n",
    "2.\t[Create a Keras model](#model)\n",
    "3.  [Train the model](#train)\n",
    "4.\t[Generate adversarial samples for a robustness check](#art)\n",
    "5.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "- To store model and training data, this notebook requires a [Cloud Object Storage (COS)](https://console.bluemix.net/catalog/services/cloud-object-storage) instance (a *lite plan* is offered and information about how to order storage is [here](https://dataplatform.ibm.com/docs/content/analyze-data/ml_dlaas_object_store.html)).\n",
    "    - After you create COS instance, go to your COS dashboard.\n",
    "    - Get the **Endpoint** tab in the COS instance's dashboard.\n",
    "    - You also need the IBM Cloud authorization endpoint to be able to create COS resource object.\n",
    "    - In the **Service credentials** tab, click **New Credential+**.\n",
    "    - Add the \"[HMAC](https://console.bluemix.net/docs/services/cloud-object-storage/hmac/credentials.html#using-hmac-credentials)\" **inline configuration parameter**: `{\"HMAC\":true}`, click **Add**.\n",
    "\n",
    "    This configuration parameter adds the following section to the instance credentials, (for use later in this notebook):\n",
    "    ```\n",
    "      \"cos_hmac_keys\": {\n",
    "            \"access_key_id\": \"1234567890abcdefghijklmnopqrtsuv\",\n",
    "            \"secret_access_key\": \"0987654321zxywvutsrqponmlkjihgfedcba1234567890ab\"\n",
    "       }\n",
    "    ```\n",
    "\n",
    "- It is recommended that you run this notebook inside a Python virtual environment. Make sure you have all required libraries installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Provide your cluster name and COS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffdl_cluster_name          = \"\"  # Name of your Kubernetes cluster with FfDL deployed on it\n",
    "cos_apikey                 = \"\"  # Cloud Object Storage API KEY\n",
    "cos_hmac_access_key_id     = \"\"  # Cloud Object Storage HMAC Access Key ID\n",
    "cos_hmac_secret_access_key = \"\"  # Cloud Object Storage HMAC Secret Access Key\n",
    "cos_resource_instance_id   = \"\"  # Cloud Object Storage Resource Instance ID\n",
    "cos_service_endpoint       = \"\"  # Cloud Object Storage service endpoint, i.e. 'https://s3-api.us-geo.objectstorage.softlayer.net'\n",
    "cos_auth_endpoint          = \"\"  # Cloud Object Storage authorization endpoint, i.e. 'https://iam.bluemix.net/oidc/token' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Verify or Install Required Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required libraries are installed.\n",
      "keras>=2.1.6\r\n",
      "tensorflow>=1.8\r\n",
      "ipython>=5.0.0\r\n",
      "jupyter>=1.0.0\r\n",
      "requests>=2.12.0,<=2.18.4\r\n",
      "wget\r\n",
      "ibm-cos-sdk\r\n",
      "git+git://github.com/IBM/adversarial-robustness-toolbox@master\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def is_venv():\n",
    "    return (hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix))\n",
    "\n",
    "try:\n",
    "    import keras, tensorflow, requests, wget, ibm_boto3, art\n",
    "    print(\"All required libraries are installed.\")\n",
    "    !cat requirements.txt\n",
    "except ModuleNotFoundError:\n",
    "    if is_venv:\n",
    "        print(\"Installing required libraries into virtual environment.\")\n",
    "        !python -m pip install -r requirements.txt\n",
    "    else:\n",
    "        print(\"Please install the required libraries.\")\n",
    "        !cat requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Connect to Cloud Object Storage  (COS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your COS credentials in the following cell. You can find these credentials in your COS instance dashboard under the **Service credentials** tab.\n",
    "\n",
    "**Note:** the HMAC key, described in [set up the environment](#setup) is included in these credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load credentials from a file or keep this to make things as obvious as possible\n",
    "\n",
    "cos_credentials = {\n",
    "  \"apikey\": cos_apikey,\n",
    "  \"cos_hmac_keys\": {\n",
    "    \"access_key_id\": cos_hmac_access_key_id,\n",
    "    \"secret_access_key\": cos_hmac_secret_access_key\n",
    "  },\n",
    "  \"endpoints\": \"https://cos-service.bluemix.net/endpoints\",\n",
    "  \"iam_apikey_description\": \"Auto generated apikey during resource-key operation for Instance\",\n",
    "  \"iam_apikey_name\": \"auto-generated-apikey-****************************\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/****************************\",\n",
    "  \"resource_instance_id\": cos_resource_instance_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in [\"apikey\", \"resource_instance_id\"]:\n",
    "    assert cos_credentials[prop], \"'%s' must be set in 'cos_credentials'\" % prop\n",
    "    \n",
    "for prop in [\"access_key_id\", \"secret_access_key\"]:\n",
    "    assert cos_credentials[\"cos_hmac_keys\"][prop], \"'%s' must be set in 'cos_credentials'\" % prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `boto` resource to be able to write data to COS. The boto library `ibm-cos-sdk` allows Python developers to manage Cloud Object Storage (COS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config\n",
    "\n",
    "cos = ibm_boto3.resource('s3',\n",
    "                         config                  = Config(signature_version='oauth'),\n",
    "                         endpoint_url            = cos_service_endpoint,\n",
    "                         ibm_auth_endpoint       = cos_auth_endpoint,\n",
    "                         ibm_api_key_id          = cos_credentials['apikey'],\n",
    "                         ibm_service_instance_id = cos_credentials['resource_instance_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two buckets, which you will use to store training data and training results.\n",
    "\n",
    "**Note:** The bucket names must be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bucket \"training-data-37e1f443-9e20-47f7-962d-43b68c4e26a3\" ...\n",
      "Creating bucket \"training-results-37e1f443-9e20-47f7-962d-43b68c4e26a3\" ...\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "bucket_uid = str(uuid4())\n",
    "buckets = ['training-data-' + bucket_uid,\n",
    "           'training-results-' + bucket_uid]\n",
    "\n",
    "for bucket in buckets:\n",
    "        print('Creating bucket \"{}\" ...'.format(bucket))\n",
    "        try:\n",
    "            cos.create_bucket(Bucket=bucket)\n",
    "        except ibm_boto3.exceptions.ibm_botocore.client.ClientError as e:\n",
    "            print('Error: {}.'.format(e.response['Error']['Message']))\n",
    "            \n",
    "training_data_bucket = buckets[0]\n",
    "training_result_bucket = buckets[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have 2 buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Download MNIST training data and upload it to the COS buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training data and upload it to the `training-data` bucket.\n",
    "First, create a list of links for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: download original data set and convert to npz\n",
    "\n",
    "# Create a list of links.\n",
    "data_links = ['https://github.com/anupamamurthi/datasets-models/raw/master/mnist/training_data/mnist.npz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell uploads files from links to your COS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data mnist.npz ...\n",
      "mnist.npz is uploaded.\n"
     ]
    }
   ],
   "source": [
    "# Upload files from the links to COS\n",
    "from urllib.request import urlopen\n",
    "\n",
    "bucket_obj = cos.Bucket(training_data_bucket)\n",
    "\n",
    "for data_link in data_links:\n",
    "    filename=data_link.split('/')[-1]\n",
    "    print('Uploading data {} ...'.format(filename))\n",
    "    with urlopen(data_link) as data:\n",
    "        bucket_obj.upload_fileobj(data, filename)\n",
    "        print('{} is uploaded.'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the list of the created buckets and their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training-data-37e1f443-9e20-47f7-962d-43b68c4e26a3\n",
      "  File: mnist.npz, 11221.13kB\n",
      "training-results-37e1f443-9e20-47f7-962d-43b68c4e26a3\n"
     ]
    }
   ],
   "source": [
    "for bucket_name in buckets:\n",
    "    print(bucket_name)\n",
    "    bucket_obj = cos.Bucket(bucket_name)\n",
    "    for obj in bucket_obj.objects.all():\n",
    "        print(\"  File: {}, {:4.2f}kB\".format(obj.key, obj.size/1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are done with COS, and you are ready to train your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 2. Create the Keras model\n",
    "\n",
    "In this section we:\n",
    "\n",
    "- [2.1 Package the model definition](#zip)\n",
    "- [2.2 Prepare the training definition metadata](#manifest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create the Model Zip File <a id=\"zip\"></a>\n",
    "\n",
    "Let's create the model [`convolutional_keras.py`](../edit/convolutional_keras.py) and add it to a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_filename  = \"convolutional_keras.py\"\n",
    "archive_filename = 'model.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing convolutional_keras.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_filename\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    if len(argv) < 2:\n",
    "        sys.exit(\"Not enough arguments provided.\")\n",
    "\n",
    "    global image_path\n",
    "\n",
    "    i = 1\n",
    "    while i <= 2:\n",
    "        arg = str(argv[i])\n",
    "        if arg == \"--data\":\n",
    "            image_path = os.path.join(os.environ[\"DATA_DIR\"], str(argv[i+1]))\n",
    "        i += 2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv)\n",
    "\n",
    "# load mnist npz file\n",
    "f = np.load(image_path)\n",
    "x_train = f['x_train']\n",
    "y_train = f['y_train']\n",
    "x_test = f['x_test']\n",
    "y_test = f['y_test']\n",
    "f.close()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model_wt_path = os.environ[\"RESULT_DIR\"] + \"/keras_original_model.hdf5\"\n",
    "model.save(model_wt_path)\n",
    "print(\"Model saved to file: %s\" % model_wt_path)\n",
    "\n",
    "model_def_path = os.environ[\"RESULT_DIR\"] + \"/keras_original_model.json\"\n",
    "model_json = model.to_json()\n",
    "with open(model_def_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"Model definition saved to file: %s\" % model_def_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: convolutional_keras.py (deflated 60%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r {archive_filename} {script_filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Prepare the Training Definition Metadata <a id=\"manifest\"></a>\n",
    "- *FfDL* does not have a *Keras* community image so we need to `pip`-install *Keras* prior to running the `training_command` \n",
    "- Your COS credentials are referenced in the `data_stores` > `connection` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "training_command = \"pip3 install keras; python3 convolutional_keras.py --data ${DATA_DIR}/mnist.npz\"\n",
    "\n",
    "manifest = {\n",
    "  \"name\": \"keras_digit_recognition\",\n",
    "  \"description\": \"Hand-written Digit Recognition Training\",\n",
    "  \"version\": \"1.0\",\n",
    "  \"gpus\": 0,\n",
    "  \"cpus\": 2,\n",
    "  \"memory\": \"2Gb\",\n",
    "  \"data_stores\": [\n",
    "    {\n",
    "      \"id\": \"sl-internal-os\",\n",
    "      \"type\": \"s3_datastore\",\n",
    "      \"training_data\": {\n",
    "        \"container\": training_data_bucket\n",
    "      },\n",
    "      \"training_results\": {\n",
    "        \"container\": training_result_bucket\n",
    "      },\n",
    "      \"connection\": {\n",
    "        \"type\": \"s3_datastore\",\n",
    "        \"auth_url\": cos_service_endpoint,\n",
    "        \"user_name\": cos_credentials['cos_hmac_keys']['access_key_id'],\n",
    "        \"password\": cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"framework\": {\n",
    "    \"name\": \"tensorflow\",\n",
    "    \"version\": \"1.5.0-py3\",\n",
    "    \"command\": training_command\n",
    "  },\n",
    "  \"evaluation_metrics\": {\n",
    "    \"type\": \"tensorboard\",\n",
    "    \"in\": \"$JOB_STATE_DIR/logs/tb\"\n",
    "  }\n",
    "}\n",
    "\n",
    "yaml.dump(manifest, open(\"manifest.yml\", \"w\"), default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model<a id=\"train\"></a>\n",
    "\n",
    "In this section, learn how to:\n",
    "- [3.1 Setup the command line environment](#cmd_setup)\n",
    "- [3.2 Train the model in the background](#backg)\n",
    "- [3.3 Monitor the training log](#log)\n",
    "- [3.4 Cancel the training](#cancel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Setup the command line environment <a id=\"cmd_setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Kubernetes cluster configuration using the [BlueMix CLI](https://console.bluemix.net/docs/cli/index.html#overview). Make sure your machine is logged in with `bx login`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VM_TYPE=ibmcloud\n",
      "env: CLUSTER_NAME=ffdl-with-art\n"
     ]
    }
   ],
   "source": [
    "%env VM_TYPE = ibmcloud\n",
    "%env CLUSTER_NAME $ffdl_cluster_name \n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "    cluster_config = !bx cs cluster-config {os.environ[\"CLUSTER_NAME\"]} | grep \"export KUBECONFIG=\"\n",
    "    os.environ[\"KUBECONFIG\"] = cluster_config[-1].split(\"=\")[-1]\n",
    "except IndexError:\n",
    "    print(\"The cluster %s could not be found.\" % os.environ[\"CLUSTER_NAME\"])\n",
    "    print(\"Run 'bx cs clusters' to list all clusters you have access to.\")\n",
    "    #!bx cs clusters\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the AWS command with endpoint and credentials and show the list of buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.environ[\"AWS_DEFAULT_REGION\"]    = \"us-east-1\"\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"]     = cos_credentials[\"cos_hmac_keys\"][\"access_key_id\"]\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = cos_credentials[\"cos_hmac_keys\"][\"secret_access_key\"]\n",
    "\n",
    "# s3_endpoint_url     = cos_service_endpoint                   \n",
    "# os.environ[\"s3cmd\"] = \"aws --endpoint-url=%s s3\" % s3_endpoint_url\n",
    "\n",
    "# !$s3cmd ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the DLaaS URL, username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir   = os.getcwd()\n",
    "ffdl_root_dir  = notebook_dir.replace(\"/etc/notebooks/art\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLAAS_URL=http://169.48.201.210:30020\n",
      "env: DLAAS_USERNAME=test-user\n",
      "env: DLAAS_PASSWORD=test\n"
     ]
    }
   ],
   "source": [
    "node_ip        = !(cd {ffdl_root_dir} && make --no-print-directory kubernetes-ip)\n",
    "restapi_port   = !kubectl get service ffdl-restapi -o jsonpath='{.spec.ports[0].nodePort}'\n",
    "dlaas_url      = \"http://%s:%s\" % (node_ip[0], restapi_port[0])\n",
    "\n",
    "%env DLAAS_URL $dlaas_url\n",
    "%env DLAAS_USERNAME = test-user\n",
    "%env DLAAS_PASSWORD = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the correct CLI for your machine and run the training job with our Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "ffdl = \"%s/cli/bin/ffdl-%s\" % (ffdl_root_dir, \"osx\" if platform.system() == \"Darwin\" else \"linux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train the model in the background<a id=\"backg\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Deploying model with manifest 'manifest.yml' and model file 'model.zip'...\",\n",
       " 'Model ID: training-NZEqlaIig',\n",
       " 'OK']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = !{ffdl} train \"manifest.yml\" \"model.zip\"\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3  Monitor the training log<a id=\"log\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting model training logs for '\u001b[1;36mtraining-NZEqlaIig\u001b[0m'...\n",
      "Status: PENDING\n",
      "Status: Not Started\n",
      "Training with training/test data at:\n",
      "  DATA_DIR: /job/training-data-37e1f443-9e20-47f7-962d-43b68c4e26a3\n",
      "  MODEL_DIR: /job/model-code\n",
      "  TRAINING_JOB: \n",
      "  TRAINING_COMMAND: pip3 install keras; python3 convolutional_keras.py --data ${DATA_DIR}/mnist.npz\n",
      "Storing trained model at:\n",
      "  RESULT_DIR: /job/training-results-37e1f443-9e20-47f7-962d-43b68c4e26a3\n",
      "Contents of $MODEL_DIR\n",
      "total 12\n",
      "drwxrwxrwx 2 6342627 root 4096 Jun  9 01:31 .\n",
      "drwxrwxrwx 6 root    root 4096 Jun  9 01:31 ..\n",
      "-rwxrwxrwx 1 6342627 root 2650 Jun  8 18:29 convolutional_keras.py\n",
      "Contents of $DATA_DIR\n",
      "total 11232\n",
      "drwxr-xr-x 2 6342627 root     4096 Jun  9 01:31 .\n",
      "drwxrwxrwx 6 root    root     4096 Jun  9 01:31 ..\n",
      "-rw-r--r-- 1 6342627 root 11490434 Jun  9 01:29 mnist.npz\n",
      "DATA_DIR=/job/training-data-37e1f443-9e20-47f7-962d-43b68c4e26a3\n",
      "ELASTICSEARCH_PORT=tcp://172.21.40.112:9200\n",
      "ELASTICSEARCH_PORT_9200_TCP=tcp://172.21.40.112:9200\n",
      "ELASTICSEARCH_PORT_9200_TCP_ADDR=172.21.40.112\n",
      "ELASTICSEARCH_PORT_9200_TCP_PORT=9200\n",
      "ELASTICSEARCH_PORT_9200_TCP_PROTO=tcp\n",
      "ELASTICSEARCH_SERVICE_HOST=172.21.40.112\n",
      "ELASTICSEARCH_SERVICE_PORT=9200\n",
      "ELASTICSEARCH_SERVICE_PORT_HTTP=9200\n",
      "FFDL_LCM_PORT=tcp://172.21.112.20:80\n",
      "FFDL_LCM_PORT_80_TCP=tcp://172.21.112.20:80\n",
      "FFDL_LCM_PORT_80_TCP_ADDR=172.21.112.20\n",
      "FFDL_LCM_PORT_80_TCP_PORT=80\n",
      "FFDL_LCM_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_LCM_SERVICE_HOST=172.21.112.20\n",
      "FFDL_LCM_SERVICE_PORT=80\n",
      "FFDL_LCM_SERVICE_PORT_GRPC=80\n",
      "FFDL_RESTAPI_PORT=tcp://172.21.130.217:80\n",
      "FFDL_RESTAPI_PORT_80_TCP=tcp://172.21.130.217:80\n",
      "FFDL_RESTAPI_PORT_80_TCP_ADDR=172.21.130.217\n",
      "FFDL_RESTAPI_PORT_80_TCP_PORT=80\n",
      "FFDL_RESTAPI_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_RESTAPI_SERVICE_HOST=172.21.130.217\n",
      "FFDL_RESTAPI_SERVICE_PORT=80\n",
      "FFDL_RESTAPI_SERVICE_PORT_FFDL=80\n",
      "FFDL_TRAINER_PORT=tcp://172.21.226.67:80\n",
      "FFDL_TRAINER_PORT_80_TCP=tcp://172.21.226.67:80\n",
      "FFDL_TRAINER_PORT_80_TCP_ADDR=172.21.226.67\n",
      "FFDL_TRAINER_PORT_80_TCP_PORT=80\n",
      "FFDL_TRAINER_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_TRAINER_SERVICE_HOST=172.21.226.67\n",
      "FFDL_TRAINER_SERVICE_PORT=80\n",
      "FFDL_TRAINER_SERVICE_PORT_GRPC=80\n",
      "FFDL_TRAININGDATA_PORT=tcp://172.21.106.158:80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP=tcp://172.21.106.158:80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_ADDR=172.21.106.158\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_PORT=80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_TRAININGDATA_SERVICE_HOST=172.21.106.158\n",
      "FFDL_TRAININGDATA_SERVICE_PORT=80\n",
      "FFDL_TRAININGDATA_SERVICE_PORT_GRPC=80\n",
      "FFDL_UI_PORT=tcp://172.21.201.22:80\n",
      "FFDL_UI_PORT_80_TCP=tcp://172.21.201.22:80\n",
      "FFDL_UI_PORT_80_TCP_ADDR=172.21.201.22\n",
      "FFDL_UI_PORT_80_TCP_PORT=80\n",
      "FFDL_UI_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_UI_SERVICE_HOST=172.21.201.22\n",
      "FFDL_UI_SERVICE_PORT=80\n",
      "FFDL_UI_SERVICE_PORT_HTTP=80\n",
      "GPU_COUNT=0.000000\n",
      "HOME=/root\n",
      "JOB_STATE_DIR=/job\n",
      "LEARNER_ID=1\n",
      "LOG_DIR=/job/logs\n",
      "MODEL_DIR=/job/model-code\n",
      "OLDPWD=/notebooks\n",
      "PATH=/usr/local/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "PROMETHEUS_PORT=tcp://172.21.53.216:9090\n",
      "PROMETHEUS_PORT_9090_TCP=tcp://172.21.53.216:9090\n",
      "PROMETHEUS_PORT_9090_TCP_ADDR=172.21.53.216\n",
      "PROMETHEUS_PORT_9090_TCP_PORT=9090\n",
      "PROMETHEUS_PORT_9090_TCP_PROTO=tcp\n",
      "PROMETHEUS_SERVICE_HOST=172.21.53.216\n",
      "PROMETHEUS_SERVICE_PORT=9090\n",
      "PROMETHEUS_SERVICE_PORT_PROMETHEUS=9090\n",
      "PWD=/job/model-code\n",
      "PYTHONPATH=:/job/model-code\n",
      "RESULT_DIR=/job/training-results-37e1f443-9e20-47f7-962d-43b68c4e26a3\n",
      "S3_PORT=tcp://172.21.95.18:80\n",
      "S3_PORT_80_TCP=tcp://172.21.95.18:80\n",
      "S3_PORT_80_TCP_ADDR=172.21.95.18\n",
      "S3_PORT_80_TCP_PORT=80\n",
      "S3_PORT_80_TCP_PROTO=tcp\n",
      "S3_SERVICE_HOST=172.21.95.18\n",
      "S3_SERVICE_PORT=80\n",
      "SHLVL=3\n",
      "TRAINING_COMMAND=pip3 install keras; python3 convolutional_keras.py --data ${DATA_DIR}/mnist.npz\n",
      "TRAINING_ID=training-NZEqlaIig\n",
      "_=/usr/bin/env\n",
      "Sat Jun  9 01:31:59 UTC 2018: Running training job\n",
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/85/db5a2df477072b2902b0eb892feb37d88ac635d36245a72a6a69b23b383a/PyYAML-3.12.tar.gz (253kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Collecting keras-preprocessing==1.0.1 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Collecting keras-applications==1.0.2 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml: started\n",
      "  Running setup.py bdist_wheel for pyyaml: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/05/65/bdc14f2c6e09e82ae3e0f13d021e1b6b2481437ea2f207df3f\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1 pyyaml-3.12\n",
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "2018-06-09 01:32:05.837398: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "\n",
      "  128/54000 [..............................] - ETA: 6:03 - loss: 2.3382 - acc: 0.0469\n",
      "  256/54000 [..............................] - ETA: 5:10 - loss: 2.2959 - acc: 0.1172\n",
      "  384/54000 [..............................] - ETA: 4:58 - loss: 2.2550 - acc: 0.1328\n",
      "  512/54000 [..............................] - ETA: 4:45 - loss: 2.2072 - acc: 0.1875\n",
      "  640/54000 [..............................] - ETA: 4:33 - loss: 2.1548 - acc: 0.2156\n",
      "  768/54000 [..............................] - ETA: 4:28 - loss: 2.0889 - acc: 0.2487\n",
      "  896/54000 [..............................] - ETA: 4:26 - loss: 2.0252 - acc: 0.2835\n",
      " 1024/54000 [..............................] - ETA: 4:25 - loss: 2.0009 - acc: 0.2939\n",
      " 1152/54000 [..............................] - ETA: 4:22 - loss: 1.9649 - acc: 0.3134\n",
      " 1280/54000 [..............................] - ETA: 4:21 - loss: 1.9351 - acc: 0.3273\n",
      " 1408/54000 [..............................] - ETA: 4:19 - loss: 1.8885 - acc: 0.3423\n",
      " 1536/54000 [..............................] - ETA: 4:17 - loss: 1.8577 - acc: 0.3555\n",
      " 1664/54000 [..............................] - ETA: 4:16 - loss: 1.8253 - acc: 0.3744\n",
      " 1792/54000 [..............................] - ETA: 4:14 - loss: 1.7967 - acc: 0.3834\n",
      " 1920/54000 [>.............................] - ETA: 4:13 - loss: 1.7511 - acc: 0.4031\n",
      " 2048/54000 [>.............................] - ETA: 4:12 - loss: 1.6997 - acc: 0.4224\n",
      " 2176/54000 [>.............................] - ETA: 4:11 - loss: 1.6624 - acc: 0.4343\n",
      " 2304/54000 [>.............................] - ETA: 4:10 - loss: 1.6430 - acc: 0.4405\n",
      " 2432/54000 [>.............................] - ETA: 4:09 - loss: 1.6111 - acc: 0.4519\n",
      " 2560/54000 [>.............................] - ETA: 4:08 - loss: 1.5762 - acc: 0.4641\n",
      " 2688/54000 [>.............................] - ETA: 4:07 - loss: 1.5409 - acc: 0.4777\n",
      " 2816/54000 [>.............................] - ETA: 4:06 - loss: 1.5126 - acc: 0.4883\n",
      " 2944/54000 [>.............................] - ETA: 4:05 - loss: 1.4870 - acc: 0.4966\n",
      " 3072/54000 [>.............................] - ETA: 4:04 - loss: 1.4598 - acc: 0.5072\n",
      " 3200/54000 [>.............................] - ETA: 4:04 - loss: 1.4294 - acc: 0.5194\n",
      " 3328/54000 [>.............................] - ETA: 4:03 - loss: 1.4010 - acc: 0.5300\n",
      " 3456/54000 [>.............................] - ETA: 4:02 - loss: 1.3822 - acc: 0.5373\n",
      " 3584/54000 [>.............................] - ETA: 4:01 - loss: 1.3540 - acc: 0.5488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3712/54000 [=>............................] - ETA: 4:00 - loss: 1.3292 - acc: 0.5566\n",
      " 3840/54000 [=>............................] - ETA: 3:59 - loss: 1.3047 - acc: 0.5661\n",
      " 3968/54000 [=>............................] - ETA: 3:59 - loss: 1.2852 - acc: 0.5733\n",
      " 4096/54000 [=>............................] - ETA: 3:58 - loss: 1.2777 - acc: 0.5769\n",
      " 4224/54000 [=>............................] - ETA: 3:57 - loss: 1.2678 - acc: 0.5821\n",
      " 4352/54000 [=>............................] - ETA: 3:56 - loss: 1.2500 - acc: 0.5882\n",
      " 4480/54000 [=>............................] - ETA: 3:56 - loss: 1.2311 - acc: 0.5951\n",
      " 4608/54000 [=>............................] - ETA: 3:55 - loss: 1.2111 - acc: 0.6029\n",
      " 4736/54000 [=>............................] - ETA: 3:54 - loss: 1.1923 - acc: 0.6094\n",
      " 4864/54000 [=>............................] - ETA: 3:54 - loss: 1.1741 - acc: 0.6157\n",
      " 4992/54000 [=>............................] - ETA: 3:53 - loss: 1.1588 - acc: 0.6212\n",
      " 5120/54000 [=>............................] - ETA: 3:52 - loss: 1.1441 - acc: 0.6256\n",
      " 5248/54000 [=>............................] - ETA: 3:51 - loss: 1.1341 - acc: 0.6288\n",
      " 5376/54000 [=>............................] - ETA: 3:51 - loss: 1.1219 - acc: 0.6324\n",
      " 5504/54000 [==>...........................] - ETA: 3:50 - loss: 1.1105 - acc: 0.6374\n",
      " 5632/54000 [==>...........................] - ETA: 3:49 - loss: 1.0967 - acc: 0.6424\n",
      " 5760/54000 [==>...........................] - ETA: 3:49 - loss: 1.0817 - acc: 0.6476\n",
      " 5888/54000 [==>...........................] - ETA: 3:48 - loss: 1.0665 - acc: 0.6520\n",
      " 6016/54000 [==>...........................] - ETA: 3:47 - loss: 1.0523 - acc: 0.6564\n",
      " 6144/54000 [==>...........................] - ETA: 3:47 - loss: 1.0399 - acc: 0.6608\n",
      " 6272/54000 [==>...........................] - ETA: 3:46 - loss: 1.0292 - acc: 0.6641\n",
      " 6400/54000 [==>...........................] - ETA: 3:45 - loss: 1.0205 - acc: 0.6666\n",
      " 6528/54000 [==>...........................] - ETA: 3:45 - loss: 1.0118 - acc: 0.6694\n",
      " 6656/54000 [==>...........................] - ETA: 3:44 - loss: 1.0003 - acc: 0.6734\n",
      " 6784/54000 [==>...........................] - ETA: 3:43 - loss: 0.9918 - acc: 0.6764\n",
      " 6912/54000 [==>...........................] - ETA: 3:42 - loss: 0.9833 - acc: 0.6795\n",
      " 7040/54000 [==>...........................] - ETA: 3:42 - loss: 0.9738 - acc: 0.6827\n",
      " 7168/54000 [==>...........................] - ETA: 3:41 - loss: 0.9630 - acc: 0.6860\n",
      " 7296/54000 [===>..........................] - ETA: 3:41 - loss: 0.9544 - acc: 0.6891\n",
      " 7424/54000 [===>..........................] - ETA: 3:40 - loss: 0.9446 - acc: 0.6928\n",
      " 7552/54000 [===>..........................] - ETA: 3:39 - loss: 0.9358 - acc: 0.6952\n",
      " 7680/54000 [===>..........................] - ETA: 3:39 - loss: 0.9281 - acc: 0.6986\n",
      " 7808/54000 [===>..........................] - ETA: 3:38 - loss: 0.9186 - acc: 0.7021\n",
      " 7936/54000 [===>..........................] - ETA: 3:38 - loss: 0.9121 - acc: 0.7041\n",
      " 8064/54000 [===>..........................] - ETA: 3:37 - loss: 0.9048 - acc: 0.7063\n",
      " 8192/54000 [===>..........................] - ETA: 3:36 - loss: 0.8961 - acc: 0.7094\n",
      " 8320/54000 [===>..........................] - ETA: 3:36 - loss: 0.8885 - acc: 0.7118\n",
      " 8448/54000 [===>..........................] - ETA: 3:35 - loss: 0.8801 - acc: 0.7145\n",
      " 8576/54000 [===>..........................] - ETA: 3:34 - loss: 0.8743 - acc: 0.7169\n",
      " 8704/54000 [===>..........................] - ETA: 3:34 - loss: 0.8657 - acc: 0.7199\n",
      " 8832/54000 [===>..........................] - ETA: 3:33 - loss: 0.8586 - acc: 0.7224\n",
      " 8960/54000 [===>..........................] - ETA: 3:33 - loss: 0.8510 - acc: 0.7250\n",
      " 9088/54000 [====>.........................] - ETA: 3:32 - loss: 0.8430 - acc: 0.7276\n",
      " 9216/54000 [====>.........................] - ETA: 3:32 - loss: 0.8370 - acc: 0.7301\n",
      " 9344/54000 [====>.........................] - ETA: 3:31 - loss: 0.8309 - acc: 0.7323\n",
      " 9472/54000 [====>.........................] - ETA: 3:30 - loss: 0.8241 - acc: 0.7347\n",
      " 9600/54000 [====>.........................] - ETA: 3:30 - loss: 0.8170 - acc: 0.7373\n",
      " 9728/54000 [====>.........................] - ETA: 3:29 - loss: 0.8109 - acc: 0.7393\n",
      " 9856/54000 [====>.........................] - ETA: 3:28 - loss: 0.8049 - acc: 0.7413\n",
      " 9984/54000 [====>.........................] - ETA: 3:28 - loss: 0.7983 - acc: 0.7438\n",
      "10112/54000 [====>.........................] - ETA: 3:27 - loss: 0.7932 - acc: 0.7456\n",
      "10240/54000 [====>.........................] - ETA: 3:27 - loss: 0.7886 - acc: 0.7471\n",
      "10368/54000 [====>.........................] - ETA: 3:26 - loss: 0.7833 - acc: 0.7489\n",
      "10496/54000 [====>.........................] - ETA: 3:25 - loss: 0.7785 - acc: 0.7510\n",
      "10624/54000 [====>.........................] - ETA: 3:25 - loss: 0.7728 - acc: 0.7529\n",
      "10752/54000 [====>.........................] - ETA: 3:24 - loss: 0.7661 - acc: 0.7554\n",
      "10880/54000 [=====>........................] - ETA: 3:23 - loss: 0.7597 - acc: 0.7574\n",
      "11008/54000 [=====>........................] - ETA: 3:23 - loss: 0.7542 - acc: 0.7590\n",
      "11136/54000 [=====>........................] - ETA: 3:22 - loss: 0.7480 - acc: 0.7611\n",
      "11264/54000 [=====>........................] - ETA: 3:21 - loss: 0.7433 - acc: 0.7628\n",
      "11392/54000 [=====>........................] - ETA: 3:21 - loss: 0.7387 - acc: 0.7645\n",
      "11520/54000 [=====>........................] - ETA: 3:20 - loss: 0.7340 - acc: 0.7661\n",
      "11648/54000 [=====>........................] - ETA: 3:20 - loss: 0.7289 - acc: 0.7679\n",
      "11776/54000 [=====>........................] - ETA: 3:19 - loss: 0.7252 - acc: 0.7693\n",
      "11904/54000 [=====>........................] - ETA: 3:18 - loss: 0.7219 - acc: 0.7703\n",
      "12032/54000 [=====>........................] - ETA: 3:18 - loss: 0.7169 - acc: 0.7717\n",
      "12160/54000 [=====>........................] - ETA: 3:17 - loss: 0.7115 - acc: 0.7736\n",
      "12288/54000 [=====>........................] - ETA: 3:17 - loss: 0.7084 - acc: 0.7749\n",
      "12416/54000 [=====>........................] - ETA: 3:16 - loss: 0.7061 - acc: 0.7759\n",
      "12544/54000 [=====>........................] - ETA: 3:15 - loss: 0.7029 - acc: 0.7768\n",
      "12672/54000 [======>.......................] - ETA: 3:15 - loss: 0.6994 - acc: 0.7776\n",
      "12800/54000 [======>.......................] - ETA: 3:14 - loss: 0.6959 - acc: 0.7788\n",
      "12928/54000 [======>.......................] - ETA: 3:13 - loss: 0.6934 - acc: 0.7798\n",
      "13056/54000 [======>.......................] - ETA: 3:13 - loss: 0.6899 - acc: 0.7806\n",
      "13184/54000 [======>.......................] - ETA: 3:12 - loss: 0.6868 - acc: 0.7817\n",
      "13312/54000 [======>.......................] - ETA: 3:12 - loss: 0.6834 - acc: 0.7831\n",
      "13440/54000 [======>.......................] - ETA: 3:11 - loss: 0.6784 - acc: 0.7848\n",
      "13568/54000 [======>.......................] - ETA: 3:10 - loss: 0.6754 - acc: 0.7859\n",
      "13696/54000 [======>.......................] - ETA: 3:10 - loss: 0.6720 - acc: 0.7872\n",
      "13824/54000 [======>.......................] - ETA: 3:09 - loss: 0.6689 - acc: 0.7880\n",
      "13952/54000 [======>.......................] - ETA: 3:09 - loss: 0.6652 - acc: 0.7894\n",
      "14080/54000 [======>.......................] - ETA: 3:08 - loss: 0.6626 - acc: 0.7901\n",
      "14208/54000 [======>.......................] - ETA: 3:07 - loss: 0.6583 - acc: 0.7917\n",
      "14336/54000 [======>.......................] - ETA: 3:07 - loss: 0.6540 - acc: 0.7930\n",
      "14464/54000 [=======>......................] - ETA: 3:06 - loss: 0.6510 - acc: 0.7940\n",
      "14592/54000 [=======>......................] - ETA: 3:05 - loss: 0.6486 - acc: 0.7945\n",
      "14720/54000 [=======>......................] - ETA: 3:05 - loss: 0.6445 - acc: 0.7959\n",
      "14848/54000 [=======>......................] - ETA: 3:04 - loss: 0.6420 - acc: 0.7968\n",
      "14976/54000 [=======>......................] - ETA: 3:04 - loss: 0.6397 - acc: 0.7978\n",
      "15104/54000 [=======>......................] - ETA: 3:03 - loss: 0.6363 - acc: 0.7989\n",
      "15232/54000 [=======>......................] - ETA: 3:02 - loss: 0.6334 - acc: 0.8000\n",
      "15360/54000 [=======>......................] - ETA: 3:02 - loss: 0.6303 - acc: 0.8010\n",
      "15488/54000 [=======>......................] - ETA: 3:01 - loss: 0.6277 - acc: 0.8019\n",
      "15616/54000 [=======>......................] - ETA: 3:01 - loss: 0.6251 - acc: 0.8027\n",
      "15744/54000 [=======>......................] - ETA: 3:00 - loss: 0.6226 - acc: 0.8035\n",
      "15872/54000 [=======>......................] - ETA: 2:59 - loss: 0.6194 - acc: 0.8044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/54000 [=======>......................] - ETA: 2:59 - loss: 0.6168 - acc: 0.8054\n",
      "16128/54000 [=======>......................] - ETA: 2:58 - loss: 0.6138 - acc: 0.8064\n",
      "16256/54000 [========>.....................] - ETA: 2:57 - loss: 0.6101 - acc: 0.8076\n",
      "16384/54000 [========>.....................] - ETA: 2:57 - loss: 0.6064 - acc: 0.8087\n",
      "16512/54000 [========>.....................] - ETA: 2:56 - loss: 0.6032 - acc: 0.8097\n",
      "16640/54000 [========>.....................] - ETA: 2:56 - loss: 0.6015 - acc: 0.8102\n",
      "16768/54000 [========>.....................] - ETA: 2:55 - loss: 0.5996 - acc: 0.8109\n",
      "16896/54000 [========>.....................] - ETA: 2:54 - loss: 0.5968 - acc: 0.8121\n",
      "17024/54000 [========>.....................] - ETA: 2:54 - loss: 0.5937 - acc: 0.8131\n",
      "17152/54000 [========>.....................] - ETA: 2:53 - loss: 0.5915 - acc: 0.8138\n",
      "17280/54000 [========>.....................] - ETA: 2:53 - loss: 0.5890 - acc: 0.8146\n",
      "17408/54000 [========>.....................] - ETA: 2:52 - loss: 0.5863 - acc: 0.8154\n",
      "17536/54000 [========>.....................] - ETA: 2:51 - loss: 0.5836 - acc: 0.8162\n",
      "17664/54000 [========>.....................] - ETA: 2:51 - loss: 0.5809 - acc: 0.8171\n",
      "17792/54000 [========>.....................] - ETA: 2:50 - loss: 0.5782 - acc: 0.8180\n",
      "17920/54000 [========>.....................] - ETA: 2:50 - loss: 0.5756 - acc: 0.8189\n",
      "18048/54000 [=========>....................] - ETA: 2:49 - loss: 0.5734 - acc: 0.8195\n",
      "18176/54000 [=========>....................] - ETA: 2:48 - loss: 0.5706 - acc: 0.8202\n",
      "18304/54000 [=========>....................] - ETA: 2:48 - loss: 0.5690 - acc: 0.8205\n",
      "18432/54000 [=========>....................] - ETA: 2:47 - loss: 0.5669 - acc: 0.8213\n",
      "18560/54000 [=========>....................] - ETA: 2:47 - loss: 0.5657 - acc: 0.8217\n",
      "18688/54000 [=========>....................] - ETA: 2:46 - loss: 0.5641 - acc: 0.8223\n",
      "18816/54000 [=========>....................] - ETA: 2:45 - loss: 0.5620 - acc: 0.8230\n",
      "18944/54000 [=========>....................] - ETA: 2:45 - loss: 0.5600 - acc: 0.8237\n",
      "19072/54000 [=========>....................] - ETA: 2:44 - loss: 0.5578 - acc: 0.8245\n",
      "19200/54000 [=========>....................] - ETA: 2:44 - loss: 0.5558 - acc: 0.8253\n",
      "19328/54000 [=========>....................] - ETA: 2:43 - loss: 0.5536 - acc: 0.8259\n",
      "19456/54000 [=========>....................] - ETA: 2:42 - loss: 0.5514 - acc: 0.8266\n",
      "19584/54000 [=========>....................] - ETA: 2:42 - loss: 0.5486 - acc: 0.8275\n",
      "19712/54000 [=========>....................] - ETA: 2:41 - loss: 0.5467 - acc: 0.8280\n",
      "19840/54000 [==========>...................] - ETA: 2:41 - loss: 0.5447 - acc: 0.8287\n",
      "19968/54000 [==========>...................] - ETA: 2:40 - loss: 0.5427 - acc: 0.8293\n",
      "20096/54000 [==========>...................] - ETA: 2:39 - loss: 0.5400 - acc: 0.8301\n",
      "20224/54000 [==========>...................] - ETA: 2:39 - loss: 0.5382 - acc: 0.8307\n",
      "20352/54000 [==========>...................] - ETA: 2:38 - loss: 0.5358 - acc: 0.8315\n",
      "20480/54000 [==========>...................] - ETA: 2:38 - loss: 0.5337 - acc: 0.8321\n",
      "20608/54000 [==========>...................] - ETA: 2:37 - loss: 0.5317 - acc: 0.8327\n",
      "20736/54000 [==========>...................] - ETA: 2:36 - loss: 0.5298 - acc: 0.8333\n",
      "20864/54000 [==========>...................] - ETA: 2:36 - loss: 0.5273 - acc: 0.8341\n",
      "20992/54000 [==========>...................] - ETA: 2:35 - loss: 0.5256 - acc: 0.8348\n",
      "21120/54000 [==========>...................] - ETA: 2:35 - loss: 0.5231 - acc: 0.8355\n",
      "21248/54000 [==========>...................] - ETA: 2:34 - loss: 0.5214 - acc: 0.8360\n",
      "21376/54000 [==========>...................] - ETA: 2:33 - loss: 0.5200 - acc: 0.8365\n",
      "21504/54000 [==========>...................] - ETA: 2:33 - loss: 0.5185 - acc: 0.8371\n",
      "21632/54000 [===========>..................] - ETA: 2:32 - loss: 0.5164 - acc: 0.8376\n",
      "21760/54000 [===========>..................] - ETA: 2:32 - loss: 0.5145 - acc: 0.8382\n",
      "21888/54000 [===========>..................] - ETA: 2:31 - loss: 0.5124 - acc: 0.8390\n",
      "22016/54000 [===========>..................] - ETA: 2:30 - loss: 0.5104 - acc: 0.8397\n",
      "22144/54000 [===========>..................] - ETA: 2:30 - loss: 0.5087 - acc: 0.8404\n",
      "22272/54000 [===========>..................] - ETA: 2:29 - loss: 0.5070 - acc: 0.8409\n",
      "22400/54000 [===========>..................] - ETA: 2:29 - loss: 0.5046 - acc: 0.8417\n",
      "22528/54000 [===========>..................] - ETA: 2:28 - loss: 0.5030 - acc: 0.8422\n",
      "22656/54000 [===========>..................] - ETA: 2:27 - loss: 0.5012 - acc: 0.8427\n",
      "22784/54000 [===========>..................] - ETA: 2:27 - loss: 0.4990 - acc: 0.8434\n",
      "22912/54000 [===========>..................] - ETA: 2:26 - loss: 0.4977 - acc: 0.8439\n",
      "23040/54000 [===========>..................] - ETA: 2:26 - loss: 0.4971 - acc: 0.8442\n",
      "23168/54000 [===========>..................] - ETA: 2:25 - loss: 0.4956 - acc: 0.8447\n",
      "23296/54000 [===========>..................] - ETA: 2:24 - loss: 0.4948 - acc: 0.8450\n",
      "23424/54000 [============>.................] - ETA: 2:24 - loss: 0.4936 - acc: 0.8455\n",
      "23552/54000 [============>.................] - ETA: 2:23 - loss: 0.4917 - acc: 0.8460\n",
      "23680/54000 [============>.................] - ETA: 2:22 - loss: 0.4897 - acc: 0.8467\n",
      "23808/54000 [============>.................] - ETA: 2:22 - loss: 0.4880 - acc: 0.8472\n",
      "23936/54000 [============>.................] - ETA: 2:21 - loss: 0.4864 - acc: 0.8477\n",
      "24064/54000 [============>.................] - ETA: 2:21 - loss: 0.4848 - acc: 0.8482\n",
      "24192/54000 [============>.................] - ETA: 2:20 - loss: 0.4834 - acc: 0.8487\n",
      "24320/54000 [============>.................] - ETA: 2:19 - loss: 0.4820 - acc: 0.8491\n",
      "24448/54000 [============>.................] - ETA: 2:19 - loss: 0.4801 - acc: 0.8498\n",
      "24576/54000 [============>.................] - ETA: 2:18 - loss: 0.4786 - acc: 0.8502\n",
      "24704/54000 [============>.................] - ETA: 2:18 - loss: 0.4768 - acc: 0.8508\n",
      "24832/54000 [============>.................] - ETA: 2:17 - loss: 0.4753 - acc: 0.8512\n",
      "24960/54000 [============>.................] - ETA: 2:16 - loss: 0.4741 - acc: 0.8516\n",
      "25088/54000 [============>.................] - ETA: 2:16 - loss: 0.4724 - acc: 0.8521\n",
      "25216/54000 [=============>................] - ETA: 2:15 - loss: 0.4705 - acc: 0.8528\n",
      "25344/54000 [=============>................] - ETA: 2:15 - loss: 0.4694 - acc: 0.8532\n",
      "25472/54000 [=============>................] - ETA: 2:14 - loss: 0.4678 - acc: 0.8536\n",
      "25600/54000 [=============>................] - ETA: 2:13 - loss: 0.4659 - acc: 0.8543\n",
      "25728/54000 [=============>................] - ETA: 2:13 - loss: 0.4645 - acc: 0.8548\n",
      "25856/54000 [=============>................] - ETA: 2:12 - loss: 0.4632 - acc: 0.8552\n",
      "25984/54000 [=============>................] - ETA: 2:12 - loss: 0.4613 - acc: 0.8558\n",
      "26112/54000 [=============>................] - ETA: 2:11 - loss: 0.4605 - acc: 0.8560\n",
      "26240/54000 [=============>................] - ETA: 2:10 - loss: 0.4603 - acc: 0.8562\n",
      "26368/54000 [=============>................] - ETA: 2:10 - loss: 0.4591 - acc: 0.8566\n",
      "26496/54000 [=============>................] - ETA: 2:09 - loss: 0.4583 - acc: 0.8570\n",
      "26624/54000 [=============>................] - ETA: 2:09 - loss: 0.4571 - acc: 0.8574\n",
      "26752/54000 [=============>................] - ETA: 2:08 - loss: 0.4554 - acc: 0.8580\n",
      "26880/54000 [=============>................] - ETA: 2:07 - loss: 0.4540 - acc: 0.8584\n",
      "27008/54000 [==============>...............] - ETA: 2:07 - loss: 0.4523 - acc: 0.8589\n",
      "27136/54000 [==============>...............] - ETA: 2:06 - loss: 0.4509 - acc: 0.8593\n",
      "27264/54000 [==============>...............] - ETA: 2:06 - loss: 0.4495 - acc: 0.8597\n",
      "27392/54000 [==============>...............] - ETA: 2:05 - loss: 0.4480 - acc: 0.8601\n",
      "27520/54000 [==============>...............] - ETA: 2:04 - loss: 0.4470 - acc: 0.8604\n",
      "27648/54000 [==============>...............] - ETA: 2:04 - loss: 0.4462 - acc: 0.8607\n",
      "27776/54000 [==============>...............] - ETA: 2:03 - loss: 0.4451 - acc: 0.8609\n",
      "27904/54000 [==============>...............] - ETA: 2:03 - loss: 0.4439 - acc: 0.8613\n",
      "28032/54000 [==============>...............] - ETA: 2:02 - loss: 0.4427 - acc: 0.8617\n",
      "28160/54000 [==============>...............] - ETA: 2:01 - loss: 0.4416 - acc: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28288/54000 [==============>...............] - ETA: 2:01 - loss: 0.4403 - acc: 0.8623\n",
      "28416/54000 [==============>...............] - ETA: 2:00 - loss: 0.4392 - acc: 0.8626\n",
      "28544/54000 [==============>...............] - ETA: 2:00 - loss: 0.4381 - acc: 0.8629\n",
      "28672/54000 [==============>...............] - ETA: 1:59 - loss: 0.4372 - acc: 0.8632\n",
      "28800/54000 [===============>..............] - ETA: 1:58 - loss: 0.4358 - acc: 0.8637\n",
      "28928/54000 [===============>..............] - ETA: 1:58 - loss: 0.4347 - acc: 0.8640\n",
      "29056/54000 [===============>..............] - ETA: 1:57 - loss: 0.4333 - acc: 0.8644\n",
      "29184/54000 [===============>..............] - ETA: 1:56 - loss: 0.4324 - acc: 0.8648\n",
      "29312/54000 [===============>..............] - ETA: 1:56 - loss: 0.4312 - acc: 0.8651\n",
      "29440/54000 [===============>..............] - ETA: 1:55 - loss: 0.4296 - acc: 0.8657\n",
      "29568/54000 [===============>..............] - ETA: 1:55 - loss: 0.4287 - acc: 0.8660\n",
      "29696/54000 [===============>..............] - ETA: 1:54 - loss: 0.4275 - acc: 0.8662\n",
      "29824/54000 [===============>..............] - ETA: 1:53 - loss: 0.4266 - acc: 0.8666\n",
      "29952/54000 [===============>..............] - ETA: 1:53 - loss: 0.4253 - acc: 0.8670\n",
      "30080/54000 [===============>..............] - ETA: 1:52 - loss: 0.4243 - acc: 0.8673\n",
      "30208/54000 [===============>..............] - ETA: 1:52 - loss: 0.4230 - acc: 0.8676\n",
      "30336/54000 [===============>..............] - ETA: 1:51 - loss: 0.4219 - acc: 0.8679\n",
      "30464/54000 [===============>..............] - ETA: 1:50 - loss: 0.4208 - acc: 0.8683\n",
      "30592/54000 [===============>..............] - ETA: 1:50 - loss: 0.4194 - acc: 0.8688\n",
      "30720/54000 [================>.............] - ETA: 1:49 - loss: 0.4182 - acc: 0.8691\n",
      "30848/54000 [================>.............] - ETA: 1:49 - loss: 0.4170 - acc: 0.8695\n",
      "30976/54000 [================>.............] - ETA: 1:48 - loss: 0.4160 - acc: 0.8699\n",
      "31104/54000 [================>.............] - ETA: 1:47 - loss: 0.4156 - acc: 0.8701\n",
      "31232/54000 [================>.............] - ETA: 1:47 - loss: 0.4147 - acc: 0.8704\n",
      "31360/54000 [================>.............] - ETA: 1:46 - loss: 0.4144 - acc: 0.8706\n",
      "31488/54000 [================>.............] - ETA: 1:46 - loss: 0.4135 - acc: 0.8709\n",
      "31616/54000 [================>.............] - ETA: 1:45 - loss: 0.4125 - acc: 0.8712\n",
      "31744/54000 [================>.............] - ETA: 1:44 - loss: 0.4115 - acc: 0.8715\n",
      "31872/54000 [================>.............] - ETA: 1:44 - loss: 0.4109 - acc: 0.8717\n",
      "32000/54000 [================>.............] - ETA: 1:43 - loss: 0.4099 - acc: 0.8721\n",
      "32128/54000 [================>.............] - ETA: 1:43 - loss: 0.4090 - acc: 0.8724\n",
      "32256/54000 [================>.............] - ETA: 1:42 - loss: 0.4083 - acc: 0.8727\n",
      "32384/54000 [================>.............] - ETA: 1:41 - loss: 0.4076 - acc: 0.8729\n",
      "32512/54000 [=================>............] - ETA: 1:41 - loss: 0.4066 - acc: 0.8732\n",
      "32640/54000 [=================>............] - ETA: 1:40 - loss: 0.4054 - acc: 0.8737\n",
      "32768/54000 [=================>............] - ETA: 1:40 - loss: 0.4042 - acc: 0.8741\n",
      "32896/54000 [=================>............] - ETA: 1:39 - loss: 0.4029 - acc: 0.8745\n",
      "33024/54000 [=================>............] - ETA: 1:38 - loss: 0.4021 - acc: 0.8748\n",
      "33152/54000 [=================>............] - ETA: 1:38 - loss: 0.4015 - acc: 0.8750\n",
      "33280/54000 [=================>............] - ETA: 1:37 - loss: 0.4006 - acc: 0.8752\n",
      "33408/54000 [=================>............] - ETA: 1:37 - loss: 0.3996 - acc: 0.8755\n",
      "33536/54000 [=================>............] - ETA: 1:36 - loss: 0.3988 - acc: 0.8757\n",
      "33664/54000 [=================>............] - ETA: 1:35 - loss: 0.3978 - acc: 0.8760\n",
      "33792/54000 [=================>............] - ETA: 1:35 - loss: 0.3971 - acc: 0.8762\n",
      "33920/54000 [=================>............] - ETA: 1:34 - loss: 0.3959 - acc: 0.8766\n",
      "34048/54000 [=================>............] - ETA: 1:34 - loss: 0.3952 - acc: 0.8769\n",
      "34176/54000 [=================>............] - ETA: 1:33 - loss: 0.3946 - acc: 0.8770\n",
      "34304/54000 [==================>...........] - ETA: 1:32 - loss: 0.3934 - acc: 0.8774\n",
      "34432/54000 [==================>...........] - ETA: 1:32 - loss: 0.3925 - acc: 0.8777\n",
      "34560/54000 [==================>...........] - ETA: 1:31 - loss: 0.3917 - acc: 0.8780\n",
      "34688/54000 [==================>...........] - ETA: 1:30 - loss: 0.3908 - acc: 0.8783\n",
      "34816/54000 [==================>...........] - ETA: 1:30 - loss: 0.3897 - acc: 0.8786\n",
      "34944/54000 [==================>...........] - ETA: 1:29 - loss: 0.3886 - acc: 0.8790\n",
      "35072/54000 [==================>...........] - ETA: 1:29 - loss: 0.3877 - acc: 0.8793\n",
      "35200/54000 [==================>...........] - ETA: 1:28 - loss: 0.3866 - acc: 0.8796\n",
      "35328/54000 [==================>...........] - ETA: 1:27 - loss: 0.3854 - acc: 0.8800\n",
      "35456/54000 [==================>...........] - ETA: 1:27 - loss: 0.3845 - acc: 0.8803\n",
      "35584/54000 [==================>...........] - ETA: 1:26 - loss: 0.3836 - acc: 0.8806\n",
      "35712/54000 [==================>...........] - ETA: 1:26 - loss: 0.3830 - acc: 0.8808\n",
      "35840/54000 [==================>...........] - ETA: 1:25 - loss: 0.3827 - acc: 0.8810\n",
      "35968/54000 [==================>...........] - ETA: 1:24 - loss: 0.3820 - acc: 0.8811\n",
      "36096/54000 [===================>..........] - ETA: 1:24 - loss: 0.3812 - acc: 0.8815\n",
      "36224/54000 [===================>..........] - ETA: 1:23 - loss: 0.3804 - acc: 0.8817\n",
      "36352/54000 [===================>..........] - ETA: 1:23 - loss: 0.3794 - acc: 0.8820\n",
      "36480/54000 [===================>..........] - ETA: 1:22 - loss: 0.3788 - acc: 0.8821\n",
      "36608/54000 [===================>..........] - ETA: 1:21 - loss: 0.3779 - acc: 0.8825\n",
      "36736/54000 [===================>..........] - ETA: 1:21 - loss: 0.3770 - acc: 0.8827\n",
      "36864/54000 [===================>..........] - ETA: 1:20 - loss: 0.3764 - acc: 0.8830\n",
      "36992/54000 [===================>..........] - ETA: 1:20 - loss: 0.3756 - acc: 0.8832\n",
      "37120/54000 [===================>..........] - ETA: 1:19 - loss: 0.3747 - acc: 0.8835\n",
      "37248/54000 [===================>..........] - ETA: 1:18 - loss: 0.3740 - acc: 0.8836\n",
      "37376/54000 [===================>..........] - ETA: 1:18 - loss: 0.3732 - acc: 0.8839\n",
      "37504/54000 [===================>..........] - ETA: 1:17 - loss: 0.3727 - acc: 0.8840\n",
      "37632/54000 [===================>..........] - ETA: 1:17 - loss: 0.3720 - acc: 0.8842\n",
      "37760/54000 [===================>..........] - ETA: 1:16 - loss: 0.3716 - acc: 0.8844\n",
      "37888/54000 [====================>.........] - ETA: 1:15 - loss: 0.3713 - acc: 0.8845\n",
      "38016/54000 [====================>.........] - ETA: 1:15 - loss: 0.3706 - acc: 0.8847\n",
      "38144/54000 [====================>.........] - ETA: 1:14 - loss: 0.3697 - acc: 0.8850\n",
      "38272/54000 [====================>.........] - ETA: 1:14 - loss: 0.3688 - acc: 0.8853\n",
      "38400/54000 [====================>.........] - ETA: 1:13 - loss: 0.3679 - acc: 0.8856\n",
      "38528/54000 [====================>.........] - ETA: 1:12 - loss: 0.3671 - acc: 0.8859\n",
      "38656/54000 [====================>.........] - ETA: 1:12 - loss: 0.3663 - acc: 0.8861\n",
      "38784/54000 [====================>.........] - ETA: 1:11 - loss: 0.3655 - acc: 0.8863\n",
      "38912/54000 [====================>.........] - ETA: 1:11 - loss: 0.3647 - acc: 0.8865\n",
      "39040/54000 [====================>.........] - ETA: 1:10 - loss: 0.3639 - acc: 0.8868\n",
      "39168/54000 [====================>.........] - ETA: 1:09 - loss: 0.3634 - acc: 0.8869\n",
      "39296/54000 [====================>.........] - ETA: 1:09 - loss: 0.3628 - acc: 0.8872\n",
      "39424/54000 [====================>.........] - ETA: 1:08 - loss: 0.3624 - acc: 0.8873\n",
      "39552/54000 [====================>.........] - ETA: 1:08 - loss: 0.3620 - acc: 0.8874\n",
      "39680/54000 [=====================>........] - ETA: 1:07 - loss: 0.3615 - acc: 0.8875\n",
      "39808/54000 [=====================>........] - ETA: 1:06 - loss: 0.3605 - acc: 0.8879\n",
      "39936/54000 [=====================>........] - ETA: 1:06 - loss: 0.3596 - acc: 0.8881\n",
      "40064/54000 [=====================>........] - ETA: 1:05 - loss: 0.3590 - acc: 0.8884\n",
      "40192/54000 [=====================>........] - ETA: 1:05 - loss: 0.3583 - acc: 0.8886\n",
      "40320/54000 [=====================>........] - ETA: 1:04 - loss: 0.3574 - acc: 0.8889\n",
      "40448/54000 [=====================>........] - ETA: 1:03 - loss: 0.3570 - acc: 0.8891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40576/54000 [=====================>........] - ETA: 1:03 - loss: 0.3565 - acc: 0.8892\n",
      "40704/54000 [=====================>........] - ETA: 1:02 - loss: 0.3561 - acc: 0.8894\n",
      "40832/54000 [=====================>........] - ETA: 1:02 - loss: 0.3554 - acc: 0.8897\n",
      "40960/54000 [=====================>........] - ETA: 1:01 - loss: 0.3546 - acc: 0.8899\n",
      "41088/54000 [=====================>........] - ETA: 1:00 - loss: 0.3539 - acc: 0.8901\n",
      "41216/54000 [=====================>........] - ETA: 1:00 - loss: 0.3531 - acc: 0.8903\n",
      "41344/54000 [=====================>........] - ETA: 59s - loss: 0.3523 - acc: 0.8906 \n",
      "41472/54000 [======================>.......] - ETA: 59s - loss: 0.3521 - acc: 0.8907\n",
      "41600/54000 [======================>.......] - ETA: 58s - loss: 0.3512 - acc: 0.8909\n",
      "41728/54000 [======================>.......] - ETA: 57s - loss: 0.3505 - acc: 0.8912\n",
      "41856/54000 [======================>.......] - ETA: 57s - loss: 0.3498 - acc: 0.8914\n",
      "41984/54000 [======================>.......] - ETA: 56s - loss: 0.3495 - acc: 0.8915\n",
      "42112/54000 [======================>.......] - ETA: 55s - loss: 0.3490 - acc: 0.8917\n",
      "42240/54000 [======================>.......] - ETA: 55s - loss: 0.3487 - acc: 0.8918\n",
      "42368/54000 [======================>.......] - ETA: 54s - loss: 0.3480 - acc: 0.8920\n",
      "42496/54000 [======================>.......] - ETA: 54s - loss: 0.3472 - acc: 0.8923\n",
      "42624/54000 [======================>.......] - ETA: 53s - loss: 0.3468 - acc: 0.8925\n",
      "42752/54000 [======================>.......] - ETA: 52s - loss: 0.3463 - acc: 0.8927\n",
      "42880/54000 [======================>.......] - ETA: 52s - loss: 0.3456 - acc: 0.8929\n",
      "43008/54000 [======================>.......] - ETA: 51s - loss: 0.3449 - acc: 0.8931\n",
      "43136/54000 [======================>.......] - ETA: 51s - loss: 0.3444 - acc: 0.8933\n",
      "43264/54000 [=======================>......] - ETA: 50s - loss: 0.3436 - acc: 0.8935\n",
      "43392/54000 [=======================>......] - ETA: 49s - loss: 0.3431 - acc: 0.8937\n",
      "43520/54000 [=======================>......] - ETA: 49s - loss: 0.3425 - acc: 0.8939\n",
      "43648/54000 [=======================>......] - ETA: 48s - loss: 0.3423 - acc: 0.8939\n",
      "43776/54000 [=======================>......] - ETA: 48s - loss: 0.3420 - acc: 0.8941\n",
      "43904/54000 [=======================>......] - ETA: 47s - loss: 0.3415 - acc: 0.8942\n",
      "44032/54000 [=======================>......] - ETA: 46s - loss: 0.3407 - acc: 0.8945\n",
      "44160/54000 [=======================>......] - ETA: 46s - loss: 0.3399 - acc: 0.8947\n",
      "44288/54000 [=======================>......] - ETA: 45s - loss: 0.3394 - acc: 0.8948\n",
      "44416/54000 [=======================>......] - ETA: 45s - loss: 0.3387 - acc: 0.8950\n",
      "44544/54000 [=======================>......] - ETA: 44s - loss: 0.3380 - acc: 0.8953\n",
      "44672/54000 [=======================>......] - ETA: 43s - loss: 0.3376 - acc: 0.8954\n",
      "44800/54000 [=======================>......] - ETA: 43s - loss: 0.3370 - acc: 0.8956\n",
      "44928/54000 [=======================>......] - ETA: 42s - loss: 0.3364 - acc: 0.8958\n",
      "45056/54000 [========================>.....] - ETA: 42s - loss: 0.3359 - acc: 0.8960\n",
      "45184/54000 [========================>.....] - ETA: 41s - loss: 0.3353 - acc: 0.8962\n",
      "45312/54000 [========================>.....] - ETA: 40s - loss: 0.3348 - acc: 0.8963\n",
      "45440/54000 [========================>.....] - ETA: 40s - loss: 0.3342 - acc: 0.8965\n",
      "45568/54000 [========================>.....] - ETA: 39s - loss: 0.3336 - acc: 0.8966\n",
      "45696/54000 [========================>.....] - ETA: 39s - loss: 0.3330 - acc: 0.8968\n",
      "45824/54000 [========================>.....] - ETA: 38s - loss: 0.3326 - acc: 0.8969\n",
      "45952/54000 [========================>.....] - ETA: 37s - loss: 0.3321 - acc: 0.8970\n",
      "46080/54000 [========================>.....] - ETA: 37s - loss: 0.3315 - acc: 0.8973\n",
      "46208/54000 [========================>.....] - ETA: 36s - loss: 0.3308 - acc: 0.8974\n",
      "46336/54000 [========================>.....] - ETA: 36s - loss: 0.3305 - acc: 0.8976\n",
      "46464/54000 [========================>.....] - ETA: 35s - loss: 0.3302 - acc: 0.8976\n",
      "46592/54000 [========================>.....] - ETA: 34s - loss: 0.3299 - acc: 0.8976\n",
      "46720/54000 [========================>.....] - ETA: 34s - loss: 0.3293 - acc: 0.8978\n",
      "46848/54000 [=========================>....] - ETA: 33s - loss: 0.3288 - acc: 0.8980\n",
      "46976/54000 [=========================>....] - ETA: 33s - loss: 0.3282 - acc: 0.8982\n",
      "47104/54000 [=========================>....] - ETA: 32s - loss: 0.3274 - acc: 0.8985\n",
      "47232/54000 [=========================>....] - ETA: 31s - loss: 0.3267 - acc: 0.8987\n",
      "47360/54000 [=========================>....] - ETA: 31s - loss: 0.3262 - acc: 0.8989\n",
      "47488/54000 [=========================>....] - ETA: 30s - loss: 0.3254 - acc: 0.8991\n",
      "47616/54000 [=========================>....] - ETA: 30s - loss: 0.3250 - acc: 0.8992\n",
      "47744/54000 [=========================>....] - ETA: 29s - loss: 0.3244 - acc: 0.8994\n",
      "47872/54000 [=========================>....] - ETA: 28s - loss: 0.3240 - acc: 0.8996\n",
      "48000/54000 [=========================>....] - ETA: 28s - loss: 0.3236 - acc: 0.8998\n",
      "48128/54000 [=========================>....] - ETA: 27s - loss: 0.3231 - acc: 0.8999\n",
      "48256/54000 [=========================>....] - ETA: 27s - loss: 0.3227 - acc: 0.9001\n",
      "48384/54000 [=========================>....] - ETA: 26s - loss: 0.3223 - acc: 0.9002\n",
      "48512/54000 [=========================>....] - ETA: 25s - loss: 0.3219 - acc: 0.9004\n",
      "48640/54000 [==========================>...] - ETA: 25s - loss: 0.3215 - acc: 0.9005\n",
      "48768/54000 [==========================>...] - ETA: 24s - loss: 0.3210 - acc: 0.9007\n",
      "48896/54000 [==========================>...] - ETA: 24s - loss: 0.3211 - acc: 0.9007\n",
      "49024/54000 [==========================>...] - ETA: 23s - loss: 0.3205 - acc: 0.9009\n",
      "49152/54000 [==========================>...] - ETA: 22s - loss: 0.3201 - acc: 0.9010\n",
      "49280/54000 [==========================>...] - ETA: 22s - loss: 0.3196 - acc: 0.9011\n",
      "49408/54000 [==========================>...] - ETA: 21s - loss: 0.3192 - acc: 0.9013\n",
      "49536/54000 [==========================>...] - ETA: 21s - loss: 0.3188 - acc: 0.9014\n",
      "49664/54000 [==========================>...] - ETA: 20s - loss: 0.3182 - acc: 0.9016\n",
      "49792/54000 [==========================>...] - ETA: 19s - loss: 0.3177 - acc: 0.9018\n",
      "49920/54000 [==========================>...] - ETA: 19s - loss: 0.3171 - acc: 0.9020\n",
      "50048/54000 [==========================>...] - ETA: 18s - loss: 0.3167 - acc: 0.9021\n",
      "50176/54000 [==========================>...] - ETA: 18s - loss: 0.3163 - acc: 0.9022\n",
      "50304/54000 [==========================>...] - ETA: 17s - loss: 0.3157 - acc: 0.9024\n",
      "50432/54000 [===========================>..] - ETA: 16s - loss: 0.3152 - acc: 0.9026\n",
      "50560/54000 [===========================>..] - ETA: 16s - loss: 0.3146 - acc: 0.9028\n",
      "50688/54000 [===========================>..] - ETA: 15s - loss: 0.3140 - acc: 0.9030\n",
      "50816/54000 [===========================>..] - ETA: 14s - loss: 0.3134 - acc: 0.9031\n",
      "50944/54000 [===========================>..] - ETA: 14s - loss: 0.3130 - acc: 0.9033\n",
      "51072/54000 [===========================>..] - ETA: 13s - loss: 0.3126 - acc: 0.9034\n",
      "51200/54000 [===========================>..] - ETA: 13s - loss: 0.3123 - acc: 0.9035\n",
      "51328/54000 [===========================>..] - ETA: 12s - loss: 0.3117 - acc: 0.9036\n",
      "51456/54000 [===========================>..] - ETA: 11s - loss: 0.3113 - acc: 0.9037\n",
      "51584/54000 [===========================>..] - ETA: 11s - loss: 0.3109 - acc: 0.9038\n",
      "51712/54000 [===========================>..] - ETA: 10s - loss: 0.3104 - acc: 0.9040\n",
      "51840/54000 [===========================>..] - ETA: 10s - loss: 0.3100 - acc: 0.9041\n",
      "51968/54000 [===========================>..] - ETA: 9s - loss: 0.3095 - acc: 0.9043 \n",
      "52096/54000 [===========================>..] - ETA: 8s - loss: 0.3092 - acc: 0.9044\n",
      "52224/54000 [============================>.] - ETA: 8s - loss: 0.3088 - acc: 0.9045\n",
      "52352/54000 [============================>.] - ETA: 7s - loss: 0.3082 - acc: 0.9047\n",
      "52480/54000 [============================>.] - ETA: 7s - loss: 0.3078 - acc: 0.9048\n",
      "52608/54000 [============================>.] - ETA: 6s - loss: 0.3072 - acc: 0.9050\n",
      "52736/54000 [============================>.] - ETA: 5s - loss: 0.3069 - acc: 0.9051\n",
      "52864/54000 [============================>.] - ETA: 5s - loss: 0.3065 - acc: 0.9052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52992/54000 [============================>.] - ETA: 4s - loss: 0.3059 - acc: 0.9054\n",
      "53120/54000 [============================>.] - ETA: 4s - loss: 0.3056 - acc: 0.9055\n",
      "53248/54000 [============================>.] - ETA: 3s - loss: 0.3053 - acc: 0.9056\n",
      "53376/54000 [============================>.] - ETA: 2s - loss: 0.3048 - acc: 0.9058\n",
      "53504/54000 [============================>.] - ETA: 2s - loss: 0.3044 - acc: 0.9059\n",
      "53632/54000 [============================>.] - ETA: 1s - loss: 0.3039 - acc: 0.9060\n",
      "53760/54000 [============================>.] - ETA: 1s - loss: 0.3036 - acc: 0.9061\n",
      "53888/54000 [============================>.] - ETA: 0s - loss: 0.3030 - acc: 0.9063\n",
      "54000/54000 [==============================] - 263s 5ms/step - loss: 0.3028 - acc: 0.9064 - val_loss: 0.0592 - val_acc: 0.9835\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Test loss: 0.061496275620907544\n",
      "Test accuracy: 0.9804\n",
      "Model saved to file: /job/training-results-37e1f443-9e20-47f7-962d-43b68c4e26a3/keras_original_model.hdf5\n",
      "Model definition saved to file: /job/training-results-37e1f443-9e20-47f7-962d-43b68c4e26a3/keras_original_model.json\n",
      "Training process finished. Exit code: 0\n",
      "rpc error: code = Unknown desc = Error: No such container: 30bf4b9cf7202140dbd3733355a22224be1076c2e0f71349f1af1561d7ecd003\n"
     ]
    }
   ],
   "source": [
    "if \"Model ID\" in out[1]:\n",
    "    model_id = out.fields()[1][-1]\n",
    "    !{ffdl} logs --follow {model_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate adversarial samples for a robustness check <a id=\"art\"></a>\n",
    "\n",
    "In this section, learn how to:\n",
    "- [4.1 Generate adversarial samples with ART (synchronously in notebook)](#artLocal)\n",
    "- [4.2 Generate adversarial samples with ART (asynchronously using FfDL)](#artWithFfDL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Generate adversarial samples with ART (synchronously in notebook) <a id=\"artLocal\"></a>\n",
    "\n",
    "This section shows how to use the ART Fast Gradient Method (FGM) to generate adversarial samples for the model previously trained synchronously in this notebook. \n",
    "\n",
    "A trained model is available in COS bucket as a result of the previous training step. ART can be used to check robustness of the trained model. \n",
    "\n",
    "Dataset used to train the model and the trained model serve as inputs to the robustness check python script. This information is available in training_data_bucket & training_result_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the original data set and the trained model from Cloud Object Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"mnist.npz\"\n",
    "weights_filename = \"keras_original_model.hdf5\"\n",
    "network_definition_filename = \"keras_original_model.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data bucket:   training-data-37e1f443-9e20-47f7-962d-43b68c4e26a3\n",
      "training result bucket: training-results-37e1f443-9e20-47f7-962d-43b68c4e26a3\n"
     ]
    }
   ],
   "source": [
    "# print COS buckets used in the previous training run\n",
    "\n",
    "print('training data bucket:  ', training_data_bucket)\n",
    "print('training result bucket:', training_result_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded keras_original_model.hdf5\n",
      "Downloaded keras_original_model.json\n"
     ]
    }
   ],
   "source": [
    "# download network definition and weights to current working directory\n",
    "\n",
    "weights_file_in_cos_bucket = os.path.join(model_id, weights_filename)\n",
    "network_definition_file_in_cos_bucket = os.path.join(model_id, network_definition_filename)\n",
    "\n",
    "bucket_obj = cos.Bucket(training_result_bucket)\n",
    "\n",
    "bucket_obj.download_file(weights_file_in_cos_bucket, weights_filename)\n",
    "print('Downloaded', weights_filename)\n",
    "\n",
    "bucket_obj.download_file(network_definition_file_in_cos_bucket, network_definition_filename)\n",
    "print('Downloaded', network_definition_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the original data set (mnist.npz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded mnist.npz\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "bucket_obj = cos.Bucket(training_data_bucket)\n",
    "bucket_obj.download_file(dataset_filename, dataset_filename)\n",
    "print('Downloaded', dataset_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & compile the model that we created using `convolutional_keras.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Definition: keras_original_model.json\n",
      "Weights:            keras_original_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "\n",
    "print('Network Definition:', network_definition_filename)\n",
    "print('Weights:           ', weights_filename)\n",
    "\n",
    "# load model\n",
    "json_file = open(network_definition_filename, 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(weights_filename)\n",
    "comp_params = {'loss': 'categorical_crossentropy',\n",
    "                       'optimizer': 'adam',\n",
    "                       'metrics': ['accuracy']}\n",
    "model.compile(**comp_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading & compiling the model, the next step is to create a KerasClassifier. ART exposes a function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ART classifier object\n",
    "from art.classifiers.keras import KerasClassifier\n",
    "\n",
    "classifier = KerasClassifier((0, 1), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell, `mnist.npz` will be loaded and pre-processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "f = np.load(dataset_filename)\n",
    "x_original = f['x_test']\n",
    "y = f['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the original (non-adversarial) sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(x_original[1], cmap='gray')\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, the numpy array is standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "x_original = np.expand_dims(x_original, axis=3)\n",
    "x_original = x_original.astype('float32') / 255\n",
    "y = np_utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell, the model will be evaluated and test accuracy will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model test loss:     6.149627626761794\n",
      "model test accuracy: 98.04\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "scores = model.evaluate(x_original, y, verbose=0)\n",
    "print('model test loss:    ', scores[0]*100)\n",
    "print('model test accuracy:', scores[1]*100)\n",
    "model_accuracy = scores[1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ART exposes many attacks like FGM, NewtonFool, DeepFool, Carlini etc. The code below shows how to use one of ART's attack methods (Fast Gradient Method or FGM) to craft adversarial samples based on x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of adversarial samples crafted: 10000\n",
      "adversarial samples saved to: etc/notebooks/art/adv_samples\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.fast_gradient import FastGradientMethod\n",
    "\n",
    "# configuration\n",
    "epsilon = 0.2\n",
    "\n",
    "# create crafter object\n",
    "crafter = FastGradientMethod(classifier, eps=epsilon)\n",
    "\n",
    "# craft samples on x_test (stored in variable x_original)\n",
    "x_adv_samples = crafter.generate(x_original)\n",
    "\n",
    "outfile = os.path.join(os.getcwd(), 'adv_samples')\n",
    "np.savez(outfile, x_original=x_original, x_adversarial=x_adv_samples, y=y)\n",
    "\n",
    "print(\"Number of adversarial samples crafted:\", len(x_adv_samples))\n",
    "print(\"adversarial samples saved to:\", outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below functions can be used for gathering metrics like model robustness, confidence metric, perturbation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "import json\n",
    "\n",
    "\n",
    "def get_metrics(model, x_original, x_adv_samples, y):\n",
    "    scores = model.evaluate(x_original, y, verbose=0)\n",
    "    model_accuracy_on_non_adversarial_samples = scores[1] * 100\n",
    "\n",
    "    y_pred = model.predict(x_original, verbose=0)\n",
    "    y_pred_adv = model.predict(x_adv_samples, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(x_adv_samples, y, verbose=0)\n",
    "    model_accuracy_on_adversarial_samples = scores[1] * 100\n",
    "\n",
    "    pert_metric = get_perturbation_metric(x_original, x_adv_samples, y_pred, y_pred_adv, ord=2)\n",
    "    conf_metric = get_confidence_metric(y_pred, y_pred_adv)\n",
    "\n",
    "    data = {\n",
    "        \"model accuracy on test data:\": model_accuracy_on_non_adversarial_samples,\n",
    "        \"model accuracy on adversarial samples\": model_accuracy_on_adversarial_samples,\n",
    "        \"reduction in confidence\": conf_metric * 100,\n",
    "        \"average perturbation\": pert_metric * 100\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_perturbation_metric(x_original, x_adv, y_pred, y_pred_adv, ord=2):\n",
    "\n",
    "    idxs = (np.argmax(y_pred_adv, axis=1) != np.argmax(y_pred, axis=1))\n",
    "\n",
    "    if np.sum(idxs) == 0.0:\n",
    "        return 0\n",
    "\n",
    "    perts_norm = la.norm((x_adv - x_original).reshape(x_original.shape[0], -1), ord, axis=1)\n",
    "    perts_norm = perts_norm[idxs]\n",
    "\n",
    "    return np.mean(perts_norm / la.norm(x_original[idxs].reshape(np.sum(idxs), -1), ord, axis=1))\n",
    "\n",
    "\n",
    "# This computes the change in confidence for all images in the test set\n",
    "def get_confidence_metric(y_pred, y_pred_adv):\n",
    "\n",
    "    y_classidx = np.argmax(y_pred, axis=1)\n",
    "    y_classconf = y_pred[np.arange(y_pred.shape[0]), y_classidx]\n",
    "\n",
    "    y_adv_classidx = np.argmax(y_pred_adv, axis=1)\n",
    "    y_adv_classconf = y_pred_adv[np.arange(y_pred_adv.shape[0]), y_adv_classidx]\n",
    "\n",
    "    idxs = (y_classidx == y_adv_classidx)\n",
    "\n",
    "    if np.sum(idxs) == 0.0:\n",
    "        return 0\n",
    "\n",
    "    idxnonzero = y_classconf != 0\n",
    "    idxs = idxs & idxnonzero\n",
    "\n",
    "    return np.mean((y_classconf[idxs] - y_adv_classconf[idxs]) / y_classconf[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will display the following\n",
    "\n",
    "1. Model accuracy on test data\n",
    "2. Model robustness on adversarial samples\n",
    "3. Reduction in confidence\n",
    "4. Perturbation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"average perturbation\": 46.828266978263855,\n",
      "    \"model accuracy on adversarial samples\": 54.120000000000005,\n",
      "    \"model accuracy on test data:\": 98.04,\n",
      "    \"reduction in confidence\": 29.92871403694153\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = get_metrics(model,x_original,x_adv_samples, y)\n",
    "\n",
    "print(json.dumps(result, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the numpy array, so that the adversarial images can be visualized\n",
    "\n",
    "x_adv = (x_adv_samples * 255).astype('int')\n",
    "x_adv = x_adv[:, :, :, 0]\n",
    "y = np.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize an adversarial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_adv[1], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Generate adversarial samples with ART (asynchronously using FfDL) <a id=\"artWithFfDL\"></a>\n",
    "\n",
    "As its name suggests, FGM is a relatively short running method to generate adversarial samples. Other attack techniques can take much longer and therefore you may want to use additional computing resources and generate adversarial samples through an asynchronous Watsom ML training request. This section shows how to gather the relevant information to execute FGM as an asynchronous FfDL training job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first create two COS buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bucket \"robustnesscheck-data-136f29a1-9735-4f6c-8901-ef9426f2aeef\" ...\n",
      "Creating bucket \"robustnesscheck-results-136f29a1-9735-4f6c-8901-ef9426f2aeef\" ...\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "bucket_uid = str(uuid4())\n",
    "buckets = ['robustnesscheck-data-' + bucket_uid,\n",
    "           'robustnesscheck-results-' + bucket_uid]\n",
    "\n",
    "for bucket in buckets:\n",
    "    print('Creating bucket \"{}\" ...'.format(bucket))\n",
    "    try:\n",
    "        cos.create_bucket(Bucket=bucket)\n",
    "    except ibm_boto3.exceptions.ibm_botocore.client.ClientError as e:\n",
    "        print('Error: {}.'.format(e.response['Error']['Message']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesscheck_data_bucket = buckets[0]\n",
    "robustnesscheck_result_bucket = buckets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload all the artifacts (`mnist.npz`, `keras_original_model.json`, `keras_original_model.hdf5`) to the `robustnesscheck_data_bucket`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.npz is uploaded to robustnesscheck-data-136f29a1-9735-4f6c-8901-ef9426f2aeef.\n",
      "keras_original_model.hdf5 is uploaded to robustnesscheck-data-136f29a1-9735-4f6c-8901-ef9426f2aeef.\n",
      "keras_original_model.json is uploaded to robustnesscheck-data-136f29a1-9735-4f6c-8901-ef9426f2aeef.\n"
     ]
    }
   ],
   "source": [
    "# upload\n",
    "\n",
    "bucket_obj = cos.Bucket(robustnesscheck_data_bucket)\n",
    "bucket_obj.upload_file(dataset_filename, dataset_filename)\n",
    "print('{} is uploaded to {}.'.format(dataset_filename, robustnesscheck_data_bucket))\n",
    "\n",
    "bucket_obj.upload_file(weights_filename, weights_filename)\n",
    "print('{} is uploaded to {}.'.format(weights_filename, robustnesscheck_data_bucket))\n",
    "\n",
    "bucket_obj = cos.Bucket(robustnesscheck_data_bucket)\n",
    "bucket_obj.upload_file(network_definition_filename, network_definition_filename)\n",
    "print('{} is uploaded to {}.'.format(network_definition_filename, robustnesscheck_data_bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create a Python script that generates adversarial samples to check robustness using FGM (Fast Gradient Method) from the ART library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_filename  = \"robustness_check.py\"\n",
    "archive_filename = 'model.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing robustness_check.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_filename\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import json\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from art.classifiers.keras import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from art.attacks.fast_gradient import FastGradientMethod\n",
    "\n",
    "\n",
    "def get_metrics(model, x_original, x_adv_samples, y):\n",
    "    scores = model.evaluate(x_original, y, verbose=0)\n",
    "    model_accuracy_on_non_adversarial_samples = scores[1] * 100\n",
    "\n",
    "    y_pred = model.predict(x_original, verbose=0)\n",
    "    y_pred_adv = model.predict(x_adv_samples, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(x_adv_samples, y, verbose=0)\n",
    "    model_accuracy_on_adversarial_samples = scores[1] * 100\n",
    "\n",
    "    pert_metric = get_perturbation_metric(x_original, x_adv_samples, y_pred, y_pred_adv, ord=2)\n",
    "    conf_metric = get_confidence_metric(y_pred, y_pred_adv)\n",
    "\n",
    "    data = {\n",
    "        \"model accuracy on test data:\": model_accuracy_on_non_adversarial_samples,\n",
    "        \"model accuracy on adversarial samples\": model_accuracy_on_adversarial_samples,\n",
    "        \"reduction in confidence\": conf_metric * 100,\n",
    "        \"average perturbation\": pert_metric * 100\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_perturbation_metric(x_original, x_adv, y_pred, y_pred_adv, ord=2):\n",
    "\n",
    "    idxs = (np.argmax(y_pred_adv, axis=1) != np.argmax(y_pred, axis=1))\n",
    "\n",
    "    if np.sum(idxs) == 0.0:\n",
    "        return 0\n",
    "\n",
    "    perts_norm = la.norm((x_adv - x_original).reshape(x_original.shape[0], -1), ord, axis=1)\n",
    "    perts_norm = perts_norm[idxs]\n",
    "\n",
    "    return np.mean(perts_norm / la.norm(x_original[idxs].reshape(np.sum(idxs), -1), ord, axis=1))\n",
    "\n",
    "\n",
    "# This computes the change in confidence for all images in the test set\n",
    "def get_confidence_metric(y_pred, y_pred_adv):\n",
    "\n",
    "    y_classidx = np.argmax(y_pred, axis=1)\n",
    "    y_classconf = y_pred[np.arange(y_pred.shape[0]), y_classidx]\n",
    "\n",
    "    y_adv_classidx = np.argmax(y_pred_adv, axis=1)\n",
    "    y_adv_classconf = y_pred_adv[np.arange(y_pred_adv.shape[0]), y_adv_classidx]\n",
    "\n",
    "    idxs = (y_classidx == y_adv_classidx)\n",
    "\n",
    "    if np.sum(idxs) == 0.0:\n",
    "        return 0\n",
    "\n",
    "    idxnonzero = y_classconf != 0\n",
    "    idxs = idxs & idxnonzero\n",
    "\n",
    "    return np.mean((y_classconf[idxs] - y_adv_classconf[idxs]) / y_classconf[idxs])\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    if len(argv) < 2:\n",
    "        sys.exit(\"Not enough arguments provided.\")\n",
    "\n",
    "    global network_definition_filename, weights_filename, dataset_filename\n",
    "\n",
    "    i = 1\n",
    "    while i <= 8:\n",
    "        arg = str(argv[i])\n",
    "        print(arg)\n",
    "        if arg == \"--data\":\n",
    "            dataset_filename = os.path.join(os.environ[\"DATA_DIR\"], str(argv[i+1]))\n",
    "        if arg == \"--networkdefinition\":\n",
    "            network_definition_filename = os.path.join(os.environ[\"DATA_DIR\"], str(argv[i+1]))\n",
    "        if arg == \"--weights\":\n",
    "            weights_filename = os.path.join(os.environ[\"DATA_DIR\"], str(argv[i+1]))\n",
    "        if arg == \"--epsilon\":\n",
    "            epsilon = float(argv[i+1])\n",
    "\n",
    "        i += 2\n",
    "\n",
    "    print(\"dataset : \", dataset_filename)\n",
    "    print(\"network definition : \", network_definition_filename)\n",
    "    print(\"weights : \" ,weights_filename)\n",
    "\n",
    "    # load & compile model\n",
    "    json_file = open(network_definition_filename, 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(model_json)\n",
    "    model.load_weights(weights_filename)\n",
    "    comp_params = {'loss': 'categorical_crossentropy',\n",
    "                   'optimizer': 'adam',\n",
    "                   'metrics': ['accuracy']}\n",
    "    model.compile(**comp_params)\n",
    "\n",
    "    # create keras classifier\n",
    "    classifier = KerasClassifier((0, 1), model)\n",
    "\n",
    "    # load data set\n",
    "    pf = np.load(dataset_filename)\n",
    "\n",
    "    x = pf['x_test']\n",
    "    y = pf['y_test']\n",
    "\n",
    "    # pre-process numpy array\n",
    "\n",
    "    x = np.expand_dims(x, axis=3)\n",
    "    x = x.astype('float32') / 255\n",
    "\n",
    "    y = np_utils.to_categorical(y, 10)\n",
    "\n",
    "    # craft adversarial samples using FGSM\n",
    "    crafter = FastGradientMethod(classifier, eps=epsilon)\n",
    "    x_samples = crafter.generate(x)\n",
    "\n",
    "    # obtain all metrics (robustness score, perturbation metric, reduction in confidence)\n",
    "    metrics = get_metrics(model, x,x_samples, y)\n",
    "\n",
    "    print(\"metrics : \", metrics)\n",
    "    \n",
    "    report_file = os.path.join(os.environ[\"RESULT_DIR\"], \"report.txt\")\n",
    "\n",
    "    with open(report_file, \"w\") as report:\n",
    "        report.write(json.dumps(metrics))\n",
    "    \n",
    "    adv_samples_file = os.path.join(os.environ[\"RESULT_DIR\"], 'adv_samples')\n",
    "    print(\"adversarial samples saved to : \", adv_samples_file)\n",
    "    np.savez(adv_samples_file, x_original=x, x_adversarial=x_samples, y=y)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a zip archive (TODO: NOT that contains the ART library along with) `robustness_check.py` code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: robustness_check.py (deflated 67%)\r\n"
     ]
    }
   ],
   "source": [
    "# create zip archive\n",
    "# TODO: exclude folder like .git ?\n",
    "# !zip model.zip -r ./adversarial-robustness-toolbox robustness_check.py -x *.git*\n",
    "!zip -r {archive_filename} {script_filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare model definition metadata. \n",
    "\n",
    "<b> Note: </b> Execution command points to `robustness_check.py` and four arguments are passed to the script.\n",
    "\n",
    "1. data (`mnist.npz`)\n",
    "2. networkdefinition (`keras_original_model.json`)\n",
    "3. weights (`keras_original_model.hdf5`)\n",
    "4. epsilon (`0.2` or `0.1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_command = \"\\\n",
    "pip3 install keras; \\\n",
    "pip install https://github.com/IBM/adversarial-robustness-toolbox/zipball/master; \\\n",
    "python3 robustness_check.py \\\n",
    "  --epsilon 0.2 \\\n",
    "  --data ${DATA_DIR}/mnist.npz \\\n",
    "  --networkdefinition ${DATA_DIR}/keras_original_model.json \\\n",
    "  --weights ${DATA_DIR}/keras_original_model.hdf5\"\n",
    "\n",
    "manifest = {\n",
    "  \"name\": \"art_robustness_check\",\n",
    "  \"description\": \"Generates adversarial samples to check robustness using FGM\",\n",
    "  \"version\": \"1.0\",\n",
    "  \"gpus\": 0,\n",
    "  \"cpus\": 2,\n",
    "  \"memory\": \"2Gb\",\n",
    "  \"data_stores\": [\n",
    "    {\n",
    "      \"id\": \"sl-internal-os\",\n",
    "      \"type\": \"s3_datastore\",\n",
    "      \"training_data\": {\n",
    "        \"container\": robustnesscheck_data_bucket\n",
    "      },\n",
    "      \"training_results\": {\n",
    "        \"container\": robustnesscheck_result_bucket\n",
    "      },\n",
    "      \"connection\": {\n",
    "        \"type\": \"s3_datastore\",\n",
    "        \"auth_url\": cos_service_endpoint,\n",
    "        \"user_name\": cos_credentials['cos_hmac_keys']['access_key_id'],\n",
    "        \"password\": cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"framework\": {\n",
    "    \"name\": \"tensorflow\",\n",
    "    \"version\": \"1.5.0-py3\",\n",
    "    \"command\": training_command\n",
    "  },\n",
    "  \"evaluation_metrics\": {\n",
    "    \"type\": \"tensorboard\",\n",
    "    \"in\": \"$JOB_STATE_DIR/logs/tb\"\n",
    "  }\n",
    "}\n",
    "\n",
    "yaml.dump(manifest, open(\"manifest.yml\", \"w\"), default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training metadata to configure the adversarial sample generation based on FGM has been gathered and can now be passed to a training job with FfDL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Deploying model with manifest 'manifest.yml' and model file 'model.zip'...\",\n",
       " 'Model ID: training-e1S2uaIig',\n",
       " 'OK']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training execution\n",
    "\n",
    "out = !{ffdl} train \"manifest.yml\" \"model.zip\"\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting model training logs for '\u001b[1;36mtraining-e1S2uaIig\u001b[0m'...\n",
      "Status: PENDING\n",
      "Status: Not Started\n",
      "Training with training/test data at:\n",
      "  DATA_DIR: /job/robustnesscheck-data-136f29a1-9735-4f6c-8901-ef9426f2aeef\n",
      "  MODEL_DIR: /job/model-code\n",
      "  TRAINING_JOB: \n",
      "  TRAINING_COMMAND: pip3 install keras; pip install https://github.com/IBM/adversarial-robustness-toolbox/zipball/master; python3 robustness_check.py   --epsilon 0.2   --data ${DATA_DIR}/mnist.npz   --networkdefinition ${DATA_DIR}/keras_original_model.json   --weights ${DATA_DIR}/keras_original_model.hdf5\n",
      "Storing trained model at:\n",
      "  RESULT_DIR: /job/robustnesscheck-results-136f29a1-9735-4f6c-8901-ef9426f2aeef\n",
      "Contents of $MODEL_DIR\n",
      "total 20\n",
      "drwxrwxrwx 2 6342627 root 4096 Jun  9 01:40 .\n",
      "drwxrwxrwx 6 root    root 4096 Jun  9 01:40 ..\n",
      "-rwxrwxrwx 1 6342627 root 2650 Jun  8 18:29 convolutional_keras.py\n",
      "-rwxrwxrwx 1 6342627 root 4560 Jun  8 18:39 robustness_check.py\n",
      "Contents of $DATA_DIR\n",
      "total 25332\n",
      "drwxr-xr-x 2 6342627 root     4096 Jun  9 01:40 .\n",
      "drwxrwxrwx 6 root    root     4096 Jun  9 01:40 ..\n",
      "-rw-r--r-- 1 6342627 root 14430768 Jun  9 01:39 keras_original_model.hdf5\n",
      "-rw-r--r-- 1 6342627 root     2813 Jun  9 01:39 keras_original_model.json\n",
      "-rw-r--r-- 1 6342627 root 11490434 Jun  9 01:39 mnist.npz\n",
      "DATA_DIR=/job/robustnesscheck-data-136f29a1-9735-4f6c-8901-ef9426f2aeef\n",
      "ELASTICSEARCH_PORT=tcp://172.21.40.112:9200\n",
      "ELASTICSEARCH_PORT_9200_TCP=tcp://172.21.40.112:9200\n",
      "ELASTICSEARCH_PORT_9200_TCP_ADDR=172.21.40.112\n",
      "ELASTICSEARCH_PORT_9200_TCP_PORT=9200\n",
      "ELASTICSEARCH_PORT_9200_TCP_PROTO=tcp\n",
      "ELASTICSEARCH_SERVICE_HOST=172.21.40.112\n",
      "ELASTICSEARCH_SERVICE_PORT=9200\n",
      "ELASTICSEARCH_SERVICE_PORT_HTTP=9200\n",
      "FFDL_LCM_PORT=tcp://172.21.112.20:80\n",
      "FFDL_LCM_PORT_80_TCP=tcp://172.21.112.20:80\n",
      "FFDL_LCM_PORT_80_TCP_ADDR=172.21.112.20\n",
      "FFDL_LCM_PORT_80_TCP_PORT=80\n",
      "FFDL_LCM_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_LCM_SERVICE_HOST=172.21.112.20\n",
      "FFDL_LCM_SERVICE_PORT=80\n",
      "FFDL_LCM_SERVICE_PORT_GRPC=80\n",
      "FFDL_RESTAPI_PORT=tcp://172.21.130.217:80\n",
      "FFDL_RESTAPI_PORT_80_TCP=tcp://172.21.130.217:80\n",
      "FFDL_RESTAPI_PORT_80_TCP_ADDR=172.21.130.217\n",
      "FFDL_RESTAPI_PORT_80_TCP_PORT=80\n",
      "FFDL_RESTAPI_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_RESTAPI_SERVICE_HOST=172.21.130.217\n",
      "FFDL_RESTAPI_SERVICE_PORT=80\n",
      "FFDL_RESTAPI_SERVICE_PORT_FFDL=80\n",
      "FFDL_TRAINER_PORT=tcp://172.21.226.67:80\n",
      "FFDL_TRAINER_PORT_80_TCP=tcp://172.21.226.67:80\n",
      "FFDL_TRAINER_PORT_80_TCP_ADDR=172.21.226.67\n",
      "FFDL_TRAINER_PORT_80_TCP_PORT=80\n",
      "FFDL_TRAINER_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_TRAINER_SERVICE_HOST=172.21.226.67\n",
      "FFDL_TRAINER_SERVICE_PORT=80\n",
      "FFDL_TRAINER_SERVICE_PORT_GRPC=80\n",
      "FFDL_TRAININGDATA_PORT=tcp://172.21.106.158:80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP=tcp://172.21.106.158:80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_ADDR=172.21.106.158\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_PORT=80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_TRAININGDATA_SERVICE_HOST=172.21.106.158\n",
      "FFDL_TRAININGDATA_SERVICE_PORT=80\n",
      "FFDL_TRAININGDATA_SERVICE_PORT_GRPC=80\n",
      "FFDL_UI_PORT=tcp://172.21.201.22:80\n",
      "FFDL_UI_PORT_80_TCP=tcp://172.21.201.22:80\n",
      "FFDL_UI_PORT_80_TCP_ADDR=172.21.201.22\n",
      "FFDL_UI_PORT_80_TCP_PORT=80\n",
      "FFDL_UI_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_UI_SERVICE_HOST=172.21.201.22\n",
      "FFDL_UI_SERVICE_PORT=80\n",
      "FFDL_UI_SERVICE_PORT_HTTP=80\n",
      "GPU_COUNT=0.000000\n",
      "HOME=/root\n",
      "JOB_STATE_DIR=/job\n",
      "LEARNER_ID=1\n",
      "LOG_DIR=/job/logs\n",
      "MODEL_DIR=/job/model-code\n",
      "OLDPWD=/notebooks\n",
      "PATH=/usr/local/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "PROMETHEUS_PORT=tcp://172.21.53.216:9090\n",
      "PROMETHEUS_PORT_9090_TCP=tcp://172.21.53.216:9090\n",
      "PROMETHEUS_PORT_9090_TCP_ADDR=172.21.53.216\n",
      "PROMETHEUS_PORT_9090_TCP_PORT=9090\n",
      "PROMETHEUS_PORT_9090_TCP_PROTO=tcp\n",
      "PROMETHEUS_SERVICE_HOST=172.21.53.216\n",
      "PROMETHEUS_SERVICE_PORT=9090\n",
      "PROMETHEUS_SERVICE_PORT_PROMETHEUS=9090\n",
      "PWD=/job/model-code\n",
      "PYTHONPATH=:/job/model-code\n",
      "RESULT_DIR=/job/robustnesscheck-results-136f29a1-9735-4f6c-8901-ef9426f2aeef\n",
      "S3_PORT=tcp://172.21.95.18:80\n",
      "S3_PORT_80_TCP=tcp://172.21.95.18:80\n",
      "S3_PORT_80_TCP_ADDR=172.21.95.18\n",
      "S3_PORT_80_TCP_PORT=80\n",
      "S3_PORT_80_TCP_PROTO=tcp\n",
      "S3_SERVICE_HOST=172.21.95.18\n",
      "S3_SERVICE_PORT=80\n",
      "SHLVL=3\n",
      "TRAINING_COMMAND=pip3 install keras; pip install https://github.com/IBM/adversarial-robustness-toolbox/zipball/master; python3 robustness_check.py   --epsilon 0.2   --data ${DATA_DIR}/mnist.npz   --networkdefinition ${DATA_DIR}/keras_original_model.json   --weights ${DATA_DIR}/keras_original_model.hdf5\n",
      "TRAINING_ID=training-e1S2uaIig\n",
      "_=/usr/bin/env\n",
      "Sat Jun  9 01:40:42 UTC 2018: Running training job\n",
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
      "Collecting keras-applications==1.0.2 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/85/db5a2df477072b2902b0eb892feb37d88ac635d36245a72a6a69b23b383a/PyYAML-3.12.tar.gz (253kB)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Collecting keras-preprocessing==1.0.1 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml: started\n",
      "  Running setup.py bdist_wheel for pyyaml: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/05/65/bdc14f2c6e09e82ae3e0f13d021e1b6b2481437ea2f207df3f\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: keras-applications, pyyaml, keras-preprocessing, keras\n",
      "Successfully installed keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1 pyyaml-3.12\n",
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "Collecting https://github.com/IBM/adversarial-robustness-toolbox/zipball/master\n",
      "  Downloading https://github.com/IBM/adversarial-robustness-toolbox/zipball/master\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.5/dist-packages (from h5py->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from h5py->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: keras-preprocessing==1.0.1 in /usr/local/lib/python3.5/dist-packages (from Keras->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from Keras->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: keras-applications==1.0.2 in /usr/local/lib/python3.5/dist-packages (from Keras->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.5/dist-packages (from matplotlib->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.5/dist-packages (from matplotlib->adversarial-robustness-toolbox==0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: adversarial-robustness-toolbox\n",
      "  Running setup.py install for adversarial-robustness-toolbox: started\n",
      "    Running setup.py install for adversarial-robustness-toolbox: finished with status 'done'\n",
      "Successfully installed adversarial-robustness-toolbox-0.1\n",
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "2018-06-09 01:40:48.673881: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "--epsilon\n",
      "--data\n",
      "--networkdefinition\n",
      "--weights\n",
      "dataset :  /job/robustnesscheck-data-136f29a1-9735-4f6c-8901-ef9426f2aeef/mnist.npz\n",
      "network definition :  /job/robustnesscheck-data-136f29a1-9735-4f6c-8901-ef9426f2aeef/keras_original_model.json\n",
      "weights :  /job/robustnesscheck-data-136f29a1-9735-4f6c-8901-ef9426f2aeef/keras_original_model.hdf5\n",
      "metrics :  {'average perturbation': 46.828266978263855, 'model accuracy on adversarial samples': 54.120000000000005, 'model accuracy on test data:': 98.04, 'reduction in confidence': 29.92871403694153}\n",
      "adversarial samples saved to :  /job/robustnesscheck-results-136f29a1-9735-4f6c-8901-ef9426f2aeef/adv_samples\n",
      "Training process finished. Exit code: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Monitor the training logs\n",
    "\n",
    "if \"Model ID\" in out[1]:\n",
    "    model_id = out.fields()[1][-1]\n",
    "    !{ffdl} logs --follow {model_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above training job will create a report (`report.txt`). The file is available in COS (bucket = `robustnesscheck_result_bucket`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"average perturbation\": 46.828266978263855,\n",
      "    \"model accuracy on adversarial samples\": 54.120000000000005,\n",
      "    \"model accuracy on test data:\": 98.04,\n",
      "    \"reduction in confidence\": 29.92871403694153\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "report_file = os.path.join(model_id, \"report.txt\")\n",
    "bucket_obj = cos.Bucket(robustnesscheck_result_bucket)\n",
    "\n",
    "bucket_obj.download_file(report_file, \"report.txt\")\n",
    "\n",
    "with open('report.txt', \"r\") as report:\n",
    "    result = json.load(report)\n",
    "    \n",
    "print(json.dumps(result, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the adversarial samples that were stored to COS using the below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading robustnesscheck-results-136f29a1-9735-4f6c-8901-ef9426f2aeef/training-e1S2uaIig/adv_samples.npz ...\n",
      "Downloaded: adv_samples_from_cos.npz\n"
     ]
    }
   ],
   "source": [
    "samples_file = os.path.join(model_id, \"adv_samples.npz\")\n",
    "print('Downloading {}/{} ...'.format(robustnesscheck_result_bucket, samples_file))\n",
    "bucket_obj = cos.Bucket(robustnesscheck_result_bucket)\n",
    "bucket_obj.download_file(samples_file, \"adv_samples_from_cos.npz\")\n",
    "print('Downloaded:', \"adv_samples_from_cos.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare original with adversarial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_adv_samples = np.load(\"adv_samples_from_cos.npz\")\n",
    "x_original    = x_adv_samples[\"x_original\"]\n",
    "x_adversarial = x_adv_samples[\"x_adversarial\"]\n",
    "x_orig = (x_original    * 255).astype('int')[:, :, :, 0]\n",
    "x_adv  = (x_adversarial * 255).astype('int')[:, :, :, 0]\n",
    "\n",
    "cols   = 10\n",
    "rows   = 2\n",
    "images = list(x_orig[:10]) + list(x_adv[:10])\n",
    "fig    = plt.figure(figsize=(16, 3))\n",
    "\n",
    "for i in range(0, len(images)):\n",
    "    fig.add_subplot(rows, cols, i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and next steps\n",
    "\n",
    "This notebook only looked at one adversarial robustness technique (FGM). ART contains many more attacks, metrics and defenses to help you understand and improve your model's robustness.  You can use this notebook as a template to experiment with all aspects of ART. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "\n",
    "- **Anupama Murthi**  (<anupama.murthi@ibm.com>)\n",
    "\n",
    "- **Vijay Arya**  (<vijay.arya@in.ibm.com>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2017, 2018 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
